# 02 // estimation param√©trique

Date de cr√©ation: July 16, 2024 11:45 PM
Modifi√©: December 28, 2024 2:13 AM

# Rappel : espace probabilis√©

## Pr√©paration : $\sigma$-alg√®bre

Une $\sigma$-alg√®bre ou tribu sur un ensemble $\Omega$ est un ensemble $\mathcal{A} \subset \mathcal P(\Omega)$ qui v√©rifie les trois propri√©t√©s suivantes. Notons que $A$ est un sous-ensemble de $\mathcal A$.

1. $\Omega \in \mathcal A$, o√π $\Omega$ est consid√©r√© l‚Äôunivers dans le contexte
2. Stabilit√© par la compl√©mentation : $A \in \mathcal A \implies A^c \in \mathcal A$
3. Stabilit√© par l‚Äôunion d√©nombrable ($\sigma$-additivit√©) : si $(A_i)_{i \ge 1} \in \mathcal A$, alors $\bigcup_{i \ge 1} A_i \in \mathcal A$.

Appliquant les lois de De Morgan avec les propri√©t√©s 2 et 3, on arrive a la stabilit√© par l‚Äôintersection d√©nombrable, car $\left( \bigcup_{i‚â•1} A_i \right)^c = \bigcap_{i‚â•1} A_i^c$.

Les deux $\sigma$-alg√®bres les plus basiques et extr√™mes sur $\Omega$ sont $\{\empty, \Omega\}$ et $\mathcal P (\Omega)$. Toute autre $\sigma$-alg√®bre reste sur ces deux extr√™mes.

### Propositions

**Lemme**. L‚Äôintersection de deux $\sigma$-alg√®bres est un $\sigma$-alg√®bre sur $\Omega$.

Soit $C \in \mathcal P(\Omega)$. Il existe une plus petite $\sigma$-alg√®bre sur $\Omega$ contenant $C$. On l‚Äôappelle la $\sigma$-alg√®bre engendr√©e par $C$ et on la note $\sigma(C)$. C‚Äôest, en fait, l‚Äôintersection des toutes les $\sigma$-alg√®bres qui contiennent $C$.

En langage naturel, $C$ est un √©v√©nement, et on cherche la plus petite $\sigma$-alg√®bre sur les r√©sultats qui contient l‚Äô√©v√©nement.

## D√©finition des espaces probabilis√©s : $\{\Omega, \mathcal A, \mathbb P\}$

Pour toute la suite, on ne se limite pas √† juste parler de V.A. enti√®res mais aussi de V.A. r√©elles. Pour cela, il faut pr√©senter les axiomes de la mani√®re suivante, et en l‚Äôaccompagnant d‚Äôun exemple avec un d√©.

Un espace probabilis√© est un concept math√©matique pour modeler une exp√©rience al√©atoire, repr√©sent√© comme un triplet $\{ \Omega, \mathcal{A}, \mathbb{P} \}$.

- $\Omega$ : l‚Äôunivers, ou l‚Äôensemble des *r√©sultats* de l‚Äôexp√©rience. Pour un d√©. : $\{1,2,3,4,5,6\}$.
- $\mathcal{A}$ : une tribu, $\sigma$-alg√®bre ou simplement l‚Äôensemble d‚Äô*√©v√©nements*. Chaque membre de cet ensemble est formellement un ‚Äú√©v√©nement‚Äù, **qui est diff√©rent des ‚Äúr√©sultats‚Äù** de $\Omega$. Normalement, on prend comme $\mathcal{A}$ l‚Äôensemble des parties de $\Omega$, c‚Äôest-√†-dire $\mathcal{P}(\Omega)$.

Par exemple, un √©v√©nement peut √™tre simplement que le d√© montre $2$, dans ce cas $\{2\} \in \mathcal{A}$, mais aussi que le d√© montre un nombre pair, donc $\{2,4,6\} \in \mathcal{A}$.
- $\mathbb{P}$ : la loi de probabilit√©s ou mesure de probabilit√©, qui est une fonction qui associe une probabilit√© √† chaque √©v√©nement‚Äîformellement $\mathcal{A} \mapsto [0,1]$‚Äî et qui v√©rifie $\mathbb{P}(X\in\Omega)$ = 1 et $\mathbb P \left( \bigcup_{i‚â•1} A_i \right) = \sum_{i‚â•1} \mathbb{P}(A_i)$, supposons que les A_i sont 2-√†-2 disjoints. Ceci implique que la fonction ou application $\mathbb P$ est $\sigma$-additive.

Continuant avec l‚Äôexemple, si on suppose un d√© non-pip√©, donc $\mathbb{P}(X \in \{2\})=\frac{1}{6}$ et $\mathbb{P}(X \text{ pair}) = \mathbb{P}(X \in \{2,4,6\}) = \frac{1}{2}$.

<aside>
üí° Lorsqu‚Äôune exp√©rience est conduite, on imagine que la ‚Äúnature‚Äù ‚Äús√©lectionne‚Äù un **r√©sultat** unique $\omega$ de l‚Äôunivers $\Omega$, supposons $\omega = 2$. Tous les **√©v√©nements** de $\mathcal{A}$ qui contiennent le **r√©sultat** $\omega$ sont dit *produits*. Par exemple, l‚Äô√©v√©nement ‚Äúle d√© montre $2$‚Äù s‚Äôest produit, mais l‚Äô√©v√©nement ‚Äúle d√© montre un nombre pair‚Äù s‚Äôest aussi produit, et de m√™me pour l‚Äô√©v√©nement ‚Äúle d√© montre un nombre premier‚Äù, car $2$ est premier.

Cette "s√©lection" se produit de telle mani√®re que, si l'exp√©rience se r√©p√©tait plusieurs fois, le nombre d'occurrences de chaque √©v√©nement comme fraction du nombre total d'exp√©riences conduites tendrait tr√®s probablement vers la probabilit√© attribu√©e √† cet √©v√©nement par la fonction de probabilit√©s $\mathbb{P}$. Ceci c‚Äôest juste la loi des grands nombres.

</aside>

On peut se demander pourquoi ne pas choisir un autre $\mathcal{A}$ diff√©rent de $\mathcal{P}(\Omega)$. Pour le cas o√π $\Omega$ est d√©nombrable, on peut se contenter toujours faisant cette choix de $\mathcal{A}$.

Par contre, pour le cas non d√©nombrable comme $\Omega = \R$, si on d√©finissait $\mathcal{A}=\mathcal{P}(\R)$, il serait faux que choisir un sous-ensemble quelconque de $\Omega$ soit un √©v√©nement. Ceci est hors du cours, mais c‚Äôest une cons√©quence du th√©or√®me d‚ÄôUlam.

Pour cette raison, dans le cas non d√©nombrable, $\mathcal{A} \subset\mathcal{P}(\Omega)$  et non $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ comme dans le cas d√©nombrable.

## Propri√©t√©s des probabilit√©s

<aside>
üí° Pour simplicit√© de notation, on note simplement $\mathbb P(a\in A) = \mathbb P(A)$.
$a$ est une variable d‚Äôint√©r√™t dont on parle souvent, donc ce n‚Äôest pas n√©cessaire de la mentionner tout le temps. $A$ peut √™tre un ensemble ou un intervalle.

</aside>

### Propri√©t√©s basiques

- $\mathbb P (\empty) = 0$.
- $\mathbb P (A^c) = 1 - \mathbb P (A)$.
- Additivit√© simple : $\mathbb P \left( \bigcup_{i=1}^n A_i \right) = \sum_{i=1}^n \mathbb P (A_i)$. Il faut que les $A_i$ soient disjoints.

### D‚Äôautres propri√©t√©s

**$\sigma$-additivit√© d‚Äôintervalles**. Imaginons que notre espace d‚Äô√©v√©nements $\mathcal A$ contient des intervalles, qu‚Äôon notera $B_n$. On en prend une famille d‚Äôintervalles et on imagine que les intervalles devient de plus en plus grandes, c‚Äôest-√†-dire, le prochain intervalle contient l‚Äôactuel, ou $B_n \subset B_{n+1}$.  Donc :

$$
\mathbb P \left( \bigcup_{n \ge 1} B_n\right ) = \lim_{n \rightarrow \infin} \mathbb P(B_n)
$$

En outre, et ignorant la condition d‚Äôagrandissement du prochain intervalle $B_{n+1}$, on a la propri√©t√© suivante. Elle n‚Äôest pas une √©galit√© stricte car il se peut que les $B_n$ ne soient pas disjoints.

$$
\mathbb P \left( \bigcup_{n \ge 1} B_n\right ) \le \sum_{n \ge 1} \mathbb P (B_n)
$$

# Motivation

## Param√®tres et statistique param√©trique

Plusieurs notions en statistique sont d√©finies √† partir de la d√©finition de param√®tre, dont sa d√©finition est relativement vague √©tant donn√© qu‚Äôil s‚Äôagit d‚Äôun concept de base. Un **param√®tre** est une quantit√© mesur√©e d‚Äôune population statistique qui r√©sume ou d√©crit un aspect de la population, comme une moyenne ou un √©cart-type.

√Ä partir de √ßa, la **statistique param√©trique** est une branche des statistiques qui suppose que les donn√©es d'√©chantillon proviennent d'une population qui peut √™tre mod√©lis√©e de mani√®re ad√©quate par une¬†distribution de probabilit√©¬†qui a un ensemble fixe de¬†param√®tres. La plupart des m√©thodes statistiques connues sont param√©triques.

<aside>
üí° **Exemple**. Si on suppose que la taille des personnes en France suit une distribution normale (ou une autre distribution connue qui accepte des param√®tres), alors un petit ensemble de param√®tres peut √™tre mesur√© (la moyenne et l‚Äô√©cart-type, dans ce cas) pour d√©crire exactement cette population.

</aside>

Dans tout probl√®me statistique, on dispose d‚Äôune observation $x$ d‚Äôun √©l√©ment al√©atoire $X$, qui est une seule variable ou un vecteur (une collection de plusieurs variables). La statistique inf√©rentielle associe cette observation √† un mod√®le statistique ou une structure statistique qui est un **espace probabilis√©** $\{\Omega, \mathcal A, \mathbb P\}$ o√π :

- $\Omega$ est l‚Äôespace des observations, les valeurs possibles de notre √©l√©ment al√©atoire $X$
- $\mathcal A$ est la tribu des √©v√©nements observables associ√©s √† $\Omega$
- $\mathbb P$ est une famille de lois de probabilit√© possibles pour $X$, d√©finie sur $\mathcal A$

Ce dernier √©l√©ment du triplet permet de d√©finir un autre ensemble important : $\mathbb F$, qui serait l‚Äôensemble des fonction de r√©partition possibles pour $X$.

Dans le cadre de la statistique param√©trique, on suppose que $\mathbb F$ est en bijection avec un ensemble de param√®tres $\Theta$ appartenant √† un espace de dimension finie $n$. Plus simplement, chaque fonction de r√©partition $F$ dans $\mathbb F$ correspond √† un unique param√®tre $\theta$ dans $\Theta$ et vice-versa.

$$
\mathbb F = \left\{F(\cdot,\theta) : \theta\in\Theta \subset \R^n \right\}
$$

Le point $\cdot$ serait √©ventuellement la place d‚Äôune variable cumulative $x$ de l‚Äô√©l√©ment al√©atoire $X$ d‚Äôint√©r√™t (on parle, finalement, d‚Äôune fonction de r√©partition). La valeur $F(x,\theta)$ serait donc ‚Äúla probabilit√© d‚Äôobserver une valeur inf√©rieur ou √©gale √† $x$ dans notre caract√©ristique d‚Äôint√©r√™t $X$‚Äîtaille, poids, etc.‚Äî, sachant que les param√®tres de la population sont $\theta$‚Äù.

On n‚Äô√©crit pas $F(x,\theta)$ sur la d√©finition de $\mathbb F$ parce que cela serait une valeur concr√®te de la fonction $F$ et ne plus une fonction en soi.

## Le probl√®me avec $\theta$

Si l‚Äôon conna√Æt la valeur de $Œ∏$, on peut ma√Ætriser la loi de probabilit√© $F(¬∑, Œ∏)$. **Mais, en pratique, la valeur de $Œ∏$ est inconnue**. Pour d√©terminer la valeur de $Œ∏$, que l‚Äôon utilisera en pratique, on proc√®de de la mani√®re suivante :

1. On utilise un √©chantillon des VAs iid. de cette loi : $\{X_1, X_2, \cdots, X_n\}$
2. On r√©alise les valeurs de l‚Äô√©chantillon : $\{X_1=x_1, X_2=x_2,  \cdots, X_n=x_n\}$
3. On calcule une certaine valeur num√©rique que l‚Äôon consid√©rera comme une valeur approch√©e de $Œ∏$ et qu‚Äôon appelle un estimateur de $Œ∏$.

Ce chapitre navigue cette question, plus pr√©cis√©ment la d√©finition de deux types d‚Äôestimations : l‚Äôestimation ponctuelle et l‚Äôestimation par intervalle de confiance.

## Notion de statistique

Une statistique est √† un √©chantillon ce qu‚Äôun param√®tre est √† une population : une certaine quantit√© num√©rique qui d√©crit un aspect de l‚Äô√©chantillon, ou tout simplement une **fonction des donn√©es**. Si $[X_i]_{1\le i\le n}=[X_1, \cdots, X_n]$ est un √©chantillon, voyons quelques exemples :

$$
\begin{align*}
&\hat\theta_1([X_i])=\bar X_n
&\text{Moyenne √©chantillonnale}
\\[8pt]
&\hat\theta_2([X_i])=\frac{1}{n}\sum_{i=1}^n(X_i-\bar X_n)^2=S^{2^\prime}_n
&\text{Variance √©chantillonnale non corrig√©e}
\\[14pt]
&\hat\theta_3([X_i])=\frac{1}{n-1}\sum_{i=1}^n(X_i-\bar X_n)^2=S^{2}_n
&\text{Variance √©chantillonnale corrig√©e}
\\[14pt]
&\hat\theta_4([X_i])=\frac{\text{Nombre de }X_i\le x}{n}=F_n(x)
&\text{R√©partition √©chantillonnale}
\\[14pt]
&\hat\theta_5([X_i])=\max([X_i])=X_{(n)}
&n-\text{i√®me statistique d'ordre}
\\[14pt]
&\hat\theta_6([X_i])=\min([X_i])=X_{(1)}
&1-\text{i√®me statistique d'ordre}
\\[14pt]
&\hat\theta_7([X_i])=X_{(n)}-X_{(1)}
&\text{√âtendue √©chantillonnale}
\end{align*}
$$

Chaque r√©alisation $[x_1, \cdots, x_n]$ de l‚Äô√©chantillon al√©atoire $[X_1,\cdots, X_n]$, qu‚Äôon appelle les donn√©es statistiques ou observations, produit une valeur de chacune des statistiques.

Le traitement th√©orique d‚Äôun probl√®me d‚Äôinf√©rence portant sur une population $X ‚àº F(x, Œ∏)$ consiste a choisir une statistique appropri√©e (par exemple, $X$ tout seul, $\bar X_n$, $S^2_n$, $X_{(n)}$) et √† associer, √† chaque valeur de la statistique choisie, une d√©cision a propos du param√®tre inconnu. La d√©cision peut prendre diff√©rentes formes, trois desquelles seront trait√©es dor√©navant :

1. **Estimation ponctuelle** : on peut d√©cider que le param√®tre a une certain valeur.
2. **Estimation par intervalle** : on peut d√©cider que le param√®tre se trouve vraisemblablement dans un certain intervalle.
3. **Test d‚Äôhypoth√®ses** : on peut d√©cider que la valeur du param√®tre est √©gale (ou n‚Äôest pas √©gale) √† un nombre fix√© d‚Äôavance.

# Estimation ponctuelle

## D√©finition

Avant d‚Äôaborder les types d‚Äôestimation ponctuelle, on doit bien la d√©finir :

- L‚Äôestimande $\theta$ est la valeur r√©alis√© du param√®tre qui nous est d‚Äôint√©r√™t.
La plupart du temps, il s‚Äôagit tout simplement d‚Äôun param√®tre de population.
- L‚Äô**estimateur** $\hat \theta$ est une r√®gle ou algorithme pour inf√©rer la vraie valeur d‚Äôun param√®tre, et il est une fonction des donn√©es, donc on √©crit $\hat \theta(x_1,\cdots,x_n)$.
La valeur r√©alis√©e de cet estimateur aurait tendance, en un certain sens, s'approcher du param√®tre inconnu.
- L‚Äôestim√© est le r√©sultat num√©rique concr√®te r√©alis√© une fois on a appliqu√© la r√®gle de l‚Äôestimateur. Celle-ci est aussi l‚Äô**estimation ponctuelle** telle quelle.

Comme exemple, il se peut qu‚Äôil nous int√©resse la moyenne d‚Äôune population $\mu$ (estimande). Donc, notre estimateur pourrait √™tre la moyenne √©chantillonnale $\bar X_n$, et donc les r√®gles sont juste d‚Äôadditionner tous les valeurs observ√©s et puis les diviser par $n$. Notre estim√© serait la valeur concr√®te que l‚Äôestimateur a pris comme une fonction des donn√©es.

## Biais d‚Äôun estimateur et convergence

Le biais d‚Äôun estimateur est d√©fini comme sa diff√©rence sa valeur esp√©r√©e avec son estimande, donc :

$$
b_n=\mathbb E [\hat\theta_n]-\theta
$$

Un estimateur est dit ‚Äúsans biais‚Äù si sa valeur esp√©r√©e est √©gale √† l‚Äôestimande ou, en √©quivalence, si le biais est nul :

$$
\text{Estimateur sans biais }\iff\mathbb E[\hat\theta_n]=\theta
$$

En plus, on peut parler d‚Äôun estimateur qui est asymptotiquement sans biais si l‚Äôesp√©rance de l‚Äôestimateur tend vers l‚Äôestimande quand n tend vers l‚Äôinfini :

$$
\text{Estimateur asymptotiquement sans biais }\iff \lim_{n\rightarrow \infin}\mathbb E[\hat\theta_n]=\theta
$$

Voyons que ce que dit l‚Äô√©quation pr√©c√©dente ce que l‚Äôesp√©rance de l‚Äôestimateur tend vers l‚Äôestimande et non pas l‚Äôestimateur lui-m√™me tend vers l‚Äôestimande. Par contre, ceci pourrait √™tre le cas. On d√©finit une suite $(\hat\theta_i)_{i\le n}$ et on dit que l‚Äôestimateur est convergente en probabilit√© √† l‚Äôestimande si :

$$
\hat\theta_n \rightarrow \theta \text{ en probabilit√©} \iff \forall \varepsilon>0, \mathbb P\left(\lim_{n\rightarrow\infin}|\hat\theta_n-\theta|<\varepsilon\right)=1
$$

**Th√©or√®me**. Tout estimateur sans biais, ou asymptotiquement sans biais, dont la variance tend vers $0$ quand $n$ tend vers l‚Äôinfini, est convergent.

Un exemple de ce dernier th√©or√®me est $\bar X_n \rightarrow \mu$ en moyenne quadratique ou d‚Äôordre $2$.

**Th√©or√®me**. Une combinaison lin√©aire *convexe* d‚Äôestimateurs sans biais est aussi un estimateur sans biais. Une combinaison lin√©aire est convexe si la somme des coefficients √©gal $1$.

## EQM et qualit√© d‚Äôun estimateur

Il faut savoir qu‚Äôil n‚Äôexiste pas un seul estimateur sans biais pour un param√®tre. Par exemple, les statistiques $X_2$, $2X_3-X_1$ et $\bar X_n$ sont tous des estimateurs sans biais de $\mu$. Donc, quel estimateur choisir ? 

<aside>
üí° **Le professeur de ce cours insiste sur le fait que, m√™me s‚Äôil y a plusieurs estimateurs de la moyenne poblationelle, il est *naturel* de s√©lectionner la moyenne √©chantillonnale comme estimation de la moyenne poblationelle**.

</aside>

Une mani√®re est de regarder l‚Äôerreur moyenne quadratique (ou MSE comme Mean Square Error en anglais) de l‚Äôestimateur par rapport √† son estimande :

$$
\begin{align*}
&\text{Var}(\hat\theta_n)=\mathbb E[(\hat\theta_n-\mathbb E[\hat\theta_n])^2]
\\
&\text{EQM}(\hat\theta_n)= \mathbb E[(\hat\theta_n-\theta)^2]=\text{var}(\hat\theta_n)+\text{biais}(\hat\theta_n)^2
\end{align*}
$$

(On peut arriver √† la derni√®re √©galit√© si on √©crit $\text{EQM}(\hat\theta_n)= \mathbb E[(\hat\theta_n-\theta)^2]=\mathbb E\left[(\hat\theta_n-\mathbb E[\hat\theta_n])+\mathbb E[\hat\theta_n]-\theta)\right]^2$ et en d√©veloppant. Ce th√©or√®me s‚Äôappelle la d√©composition de l‚Äôerreur moyen quadratique). 

Jusqu‚Äôici, l‚Äôestimateur ne dois pas forc√©ment √™tre sans biais. Un th√©or√®me important c‚Äôest que, si $\hat\theta_n$ est sans biais, donc son $\text{EQM}(\hat\theta_n)=\text{var}(\hat\theta_n)$, donc tout simplement sa variance.

**Th√©or√®me**. Si $\text{EQM}(\hat\theta_n)=0$, alors $\hat\theta_n \rightarrow \theta$ en moyenne quadratique, et donc converge en probabilit√©.

Il faut aussi dire que $b^2_n(\theta)$ est l‚Äôerreur structurelle, qui devient $0$ si $\hat\theta$ est sans biais. On peut donc voir que, en g√©n√©ral, on voudrait un estimateur sans biais.

**Note**. Dans la question o√π si on veut diminuer la variance ou le biais mais on ne peut pas diminuer les deux simultan√©ment, on fera le n√©cessaire (diminuer l‚Äôun ou l‚Äôautre) pour diminuer le **EQM**.  

### Domination : ‚Äúefficace‚Äù entre deux estimateurs sans biais

Pour comparer deux estimateurs **sans biais**, on dit que $\hat\theta_n$ est plus ‚Äúefficace‚Äù $\hat\theta_n^\prime$si et seulement si $\text{var}(\hat\theta_n) \le \text{var}(\hat\theta_n^\prime)$. Cet utilisation du mot ‚Äúefficace‚Äù sera l‚Äôutilisation dite relative. On verra une autre mani√®re d‚Äôappeler un estimateur comme efficace qui sera plus importante.

On peut avoir une id√©e de dominance aussi m√™me sans parler ‚Äòabsence de biais‚Äù. $\hat\theta_1$ ‚Äúdomine‚Äù √† $\hat\theta_2$ ssi. $\text{EQM}(\hat\theta_1) \le \text{EQM}(\hat\theta_2)$. Notons que $\hat\theta_1$ pourrait dominer $\hat\theta_2$ si le premier a un petit biais et le deuxi√®me a une grande variance.

## Borne de Cram√©r-Rao et estimateurs *efficaces*

Tout ce qui suit sera utile pour les m√©thodes de construction d‚Äôun estimateur. Tout en premier, on devra d√©finir la fonction de vraisemblance d‚Äôun √©chantillon r√©alis√© $x=[x_i]_{i\le n}$ comme $L_n\left(x|\theta\right)$. Il serait utile de voir la fonction de densit√© $f_X(x,\theta)$ √† deux variables au m√™me temps.

- Si on fixe $\theta$, on reste avec une fonction $f_X: x\mapsto f(x|\theta)$, qui est notre fonction de densit√© commune sachant qu‚Äôelle est affect√©e par les param√®tres $\theta$.
- Si on fixe la r√©alisation $x$, on reste avec une fonction $f_X : \theta \mapsto f(\theta|x)$, et c‚Äôest cette fonction ici qui est notre fonction de vraisemblance $L$.
- [Exemple avec distribution exponentielle ici](https://www.desmos.com/calculator/wy50ozzzrg). $L$ ici serait $g(x)$.

$$
L(\theta|x)=\prod_{i=1}^nf_X\left(x|\theta\right)
$$

Ayant d√©fini la fonction de vraisemblance, on peut d√©finir la [fonction de score](https://en.wikipedia.org/wiki/Score_(statistics)), qui sera le gradient de la log-vraisemblance quand les param√®tres ont les valeurs r√©alis√©es $\theta^*$ (calculer la log-vraisemblance est moins co√ªteux si la loi m√®re en question contient des puissance ou des exponentielles). Le r√©sultat est aussi un vecteur marquant la direction de plus vite croissance, et son module est le taux de croissance dans telle direction. Le score indique la sensitivit√© de la vraisemblance.

$$
\begin{align*}
&\text{Cas uniparam√©trique : } s(\theta_I)=\frac{\partial\ln L}{\partial \theta}(\theta_I)=\frac{\partial}{\partial\theta}\sum_{i=1}^n\ln\left(f_X\left(x|\theta_I\right)\right)

\\[8pt]

&\text{Cas g√©n√©rale : } s(\theta_I)=\nabla{\ln(L(\theta_I))}=\left[\frac{\partial \ln L}{\partial \theta_1}(\theta_I), \hspace{3pt}\cdots, \frac{\partial \ln L}{\partial \theta_n}(\theta_I)\right]
\end{align*}
$$

Ici, $\theta_I$ est ‚Äú$\theta$ comme input‚Äù, pour distinguer du $\theta$ comme forme diff√©rentielle.

Un point important du score **sous quelques conditions** est que, si $\theta_I$ est le vrai vecteur param√®tre de la population c√†d. $\theta_I=\theta$, l‚Äôesp√©rance du score √©valu√© √† $\theta$ est √©gal √† $0$. Ce dernier r√©sultat s‚Äôappelle l‚Äô√©quation de vraisemblence et est important pour le calcul de la variance.

$$
s(\theta_I)=\frac{\partial\ln L}{\partial \theta}(\theta_I)=0 \implies \theta_I=\theta
$$

Les conditions sont :

1. La d√©riv√©e partielle de¬†$f(x|Œ∏)$ par rapport √† $Œ∏$ existe [presque partout](https://en.wikipedia.org/wiki/Almost_everywhere).
(Il peut ne pas exister sur un ensemble nul, tant que cet ensemble ne d√©pend pas de $*Œ∏*$)
2. L'int√©grale de¬†$*f(x|Œ∏)*$ peut √™tre diff√©renci√©e sous le signe de l'int√©grale par rapport √† $*Œ∏*$, et de m√™me pour $\mathbb E[\hat\theta|\theta]$ 
3. Le¬†[support](https://en.wikipedia.org/wiki/Support_(mathematics)) de $*f(x|Œ∏)*$ ne d√©pend pas de $*Œ∏*$

Avec cette fonction, on peut cr√©er la statistique dite ‚Äú[information de Fisher](https://en.wikipedia.org/wiki/Fisher_information)‚Äù, qui quantifie l‚Äôinformation d‚Äôun param√®tre contenue dans la loi de distribution de $X$, qui d√©pend pr√©cis√©ment de $\theta$. Formellement, l‚Äôinformation est la variance du score.

$$
I(\theta)=\mathbb E\left[\left( \frac{\partial \ln L}{\partial\theta}(\theta)-\cancel{\mathbb E[s(\theta)]}^{\space0}\right)^2\right]=\int_\Omega \left( \frac{\partial \ln L}{\partial\theta}(\theta)\right)^2L(\theta|x)d\theta

\\[7pt]

$$

**Note pratique #1**. On peut √©crire la d√©finition de l‚Äôinformation de Fisher avec la fonction de densit√© du param√®tre √©tant donn√© l‚Äô√©chantillon r√©alis√© $X=x$ (c√†d. la vraisemblance $L$), ou bien avec la fonction de densit√© de l‚Äô√©chantillon √©tant donn√© le param√®tre r√©alis√© ou le vrai param√®tre. En fait, avec la fonction de densit√© de $X$ √ßa semble √™tre plus facile.

$$
I(\theta)=\mathbb E\left[\left( \frac{\partial \ln L}{\partial\theta}(\theta)\right)^2\right]=\int_\Omega \left( \frac{\partial \ln L}{\partial\theta}(\theta)\right)^2L(\theta|x)d\theta 
\\[7pt]
\text{ou, de mani√®re √©quivalente, }
\\[7pt]
I(\theta)=\mathbb E\left[\left( \frac{\partial \ln f}{\partial\theta}(x|\theta)\right)^2\right]=\int_\Omega \left( \frac{\partial \ln f}{\partial\theta}(x|\theta)\right)^2f(x|\theta)dx
$$

**Note pratique #2**. Si $\ln(L(\theta))$ est une fonction d√©rivable deux fois et la troisi√®me condition de r√©gularit√© mentionn√©e en dessus est v√©rifi√©e, on peut calculer l‚Äôinformation de Fisher d‚Äôune autre mani√®re plus pratique.

$$
\text{Plus pratique pour les calculs }: I(\theta)=\mathbb E\left[-\frac{\partial^2 \ln L}{\partial\theta^2}(\theta^*)\right]
$$

**Th√©or√®me**. L‚Äôinverse de l‚Äôinformation de Fisher d‚Äôun param√®tre $\theta$ est un minorant de la variance d‚Äôun estimateur sans biais de tel param√®tre. Telle inverse de l‚Äôinformation est appel√©e la borne de Cram√©r-Rao. Une condition est que $I(\theta)$ existe pour tout $\theta$.

$$
\text{var}(\hat\theta_n)\ge \frac{1}{I(\theta)}
$$

Finalement, on d√©finit un estimateur sans biais $\hat\theta_n$ comme *efficace* si

$$
\text{var}(\hat\theta_n)= \frac{1}{I(\theta)}
$$

### Exemple avec la distribution exponentielle

- Prend un √©chantillon de la distribution exponentielle avec $\theta=\lambda$ ind√©termin√© et une seule VA, $X$.

$$
X\sim f(x|\lambda)=\lambda e^{-\lambda x}
$$

- Puisque on a une seule VA, la fonction de vraisemblance est la m√™me que la densit√© de $X$.
    
    $$
    L(\lambda|x)=f(x|\lambda)
    $$
    
- D√©termine la log-vraisemblance, puis la fonction de score.

$$
\begin{align*}
&\ln(L(\lambda)) = \ln(\lambda)-\lambda x=\ln(\lambda)-\lambda x \implies  
s(\lambda)=\frac{\partial \ln L}{\partial \lambda}(\lambda)=\frac{1}{\lambda}-x
\end{align*}
$$

- Puis, la fonction d‚Äôinformation de Fisher.
    
    $$
    \begin{align*}
    &-\frac{\partial^2 \ln L}{\partial \lambda^2}(\lambda)=\frac{1}{\lambda^2} &&\text{Pr√©paration pour }I(\lambda)
    \\[10pt]
    &&\vdots
    \\[10pt]
    &I(\lambda)=\mathbb E \left[ -\frac{\partial^2 \ln L}{\partial \lambda^2}(\lambda)\right]
    &&\text{D√©finition de }I(\lambda)
    \\[10pt]
    &\int_\Omega \left( -\frac{\partial^2 \ln L}{\partial \lambda^2}(\lambda)\right)L(\lambda|x)dx
    &&\text{D√©finition de }\mathbb E
    \\[14pt]
    &\int_\Omega \left(\frac{1}{ \lambda^2}\right)L(\lambda|x)dx
    &&\text{Remplacement de la valeur}
    \\[14pt]
    &\frac{1}{ \lambda^2}\int_\Omega L(\lambda|x)dx
    &&\text{Constante sort de l'int√©grale}
    \end{align*}
    $$
    
    Mais, voyons que int√©grale de la densit√© dans toutes les valeurs de $x$ d√©finies doit √™tre $1$, par d√©finition. Donc, finalement :
    
    $$
    I(\lambda)=\frac{1}{ \lambda^2}\cancel{\int_\Omega f(x|\theta)dx}^{\space1}=\frac{1}{\lambda^2}
    $$
    
    On est d‚Äôaccords avec l‚Äôinfo de la distribution exponentielle sur Wikip√©dia. On est d‚Äôaccord aussi avec [ce post de MathStackExchange](https://math.stackexchange.com/questions/1899995/fisher-information-for-exponential-distribution).
    

## M√©thodes de construction d‚Äôun estimateur

<aside>
‚ùó

Phrase du prof: la m√©thode de construction de l‚Äôestimateur ne garantit pas sa qualit√© !

</aside>

### M√©thode des moments

Supposons que $Œ∏$, le param√®tre qu‚Äôon veut estimer, soit le seul param√®tre inconnu et que $\mu$ soit une fonction de $Œ∏$ : $\mu = œÜ(Œ∏)$. Comme exemple pratique, l‚Äô√©cart-type est une fonction de la moyenne.

Si $œÜ$ est bijective, elle admettra une application inverse qui nous permettra d‚Äô√©crire $Œ∏ = œÜ^{‚àí1}(\mu)$. On en conclut donc :

$$
\mu=\varphi(\theta) \hspace{10pt}\text{et}\hspace{10pt}\theta=\varphi^{-1}(\mu)\iff\hat\theta=\varphi^{-1}(\bar X_n)
$$

Le but est de exprimer la moyenne populationnelle $\mu$ comme une fonction du param√®tre $\theta$. Et, puisque la moyenne est le moment d‚Äôordre $1$ d‚Äôune variable al√©atoire, le nom de cette m√©thode est donc la m√©thode des moments.

1. On √©tablit l‚Äô√©quation : $\mu=\mathbb E[X]=\varphi(\theta)$. Les calculs viennent avec la d√©f. de $\mathbb E$.
2. On d√©termine le param√®tre th√©orique : $\theta = \varphi^{-1}(\mu)$
3. On d√©termine finalement la statistique de l‚Äôestimande avec un remplacement simple : $\hat\theta=\varphi(\hat\mu)=\varphi(\bar X)$

**Note**. L‚Äôestimateur obtenu par la m√©thode des moments n‚Äôest pas n√©cessairement sans biais.

Il est vrai que le moment le plus utilis√© en pratique est le moment d‚Äôordre $1$, c√†d. la moyenne $\mu=\mathbb E[X]$, et aussi qu‚Äôil est naturel d‚Äôestimer $\mathbb E[X]$ avec $\bar X$, la moyenne empirique des $X_i$. Cela dit, on peut le faire aussi sur $\mathbb E[X^2]$ avec la moyenne empirique des $X^2_i$, en on g√©n√©ralise avec tous les $k$-moments de $X$, $\mathbb E[X^k]$ avec $X^k_i$.

Pour avoir une meilleure notation, on note $\mu^\prime_k$ le moment d‚Äôordre $k$ de la population, puis $m^\prime_k$ serait le moment d‚Äôordre $k$ √©chantillonnale, d‚Äôo√π $\mu^\prime_1=\mathbb E[X]$ et $\lim_{n\rightarrow\infin} m^\prime_1 = \mathbb E[X]$, ce qu‚Äôon a dit sur le paragraphe pr√©c√©dent.

En plus, pour chaque $\mu^\prime_k$, on consid√®re qu‚Äôil existe une fonction $\varphi_k$ qui prend tous les param√®tres et qui nous retourne le moment d‚Äôordre $k$ de la population.

Dans le cas ou la distribution est d√©termin√©e par plus d‚Äôun param√®tre, $\theta=[\theta_1, \cdots, \theta_n]$, on pourrait tenter de calculer autant de moments que des param√®tres pour apr√®s faire un syst√®me d‚Äô√©quations. Supposons qu‚Äôon veut estimer $n$ param√®tres, donc on sait que

$$
\begin{cases}
\mu^\prime_1&=&\varphi_1(\theta_1, \cdots,\theta_k)
\\
&\vdots&
\\
\mu^\prime_k&=&\varphi_k(\theta_1, \cdots,\theta_k)
\end{cases}

\longrightarrow

\begin{cases}
m^\prime_1&=\varphi_1(\hat\theta_1,\cdots,\hat\theta_k)
\\
&\vdots
\\
m^\prime_k&=\varphi_k(\hat\theta_1,\cdots,\hat\theta_k)
\end{cases}
$$

Par exemple, pour estimer les param√®tres d‚Äôune normale :

$$
\begin{cases}
\mathbb E[X] = \mu
\\
\mathbb E[X^2] = \mu^2 + \sigma^2
\end{cases}

\rightarrow

\begin{cases}
\hat{\mathbb E}[X] = \underbrace{\frac{1}{n}\sum_{i=1}^n X_i}_{\bar {X_n}}=\hat\mu

\\[30pt]

\hat{\mathbb E}[X^2] = \frac{1}{n}\sum_{i=1}^n X_i^2=\hat{\mu^2} + \hat{\sigma^2}
\end{cases}

\\[10pts]

\text{Finalement, }
\begin{cases}
\hat \mu = \underbrace{\frac{1}{n}\sum_{i=1}^n X_i}_{\bar {X_n}}

\\[30pt]

\hat{\sigma^2} = \frac{1}{n}\sum_{i=1}^n X^2_i-\hat{\mu^2}
\end{cases}
$$

Notons que le dernier pas c‚Äôest de ‚Äúmettre un chapeau √† tout‚Äù, c√†d. de passer du param√®tre √† l‚Äôestimateur.

Rappel. $S^{2}$ est la variance ‚Äúqu‚Äôon ne veut pas‚Äù, la variance non corrig√©e. Apr√®s, on peut la corriger comme $S^{2^\prime}=\frac{n}{n-1}S^{2}$.

### M√©thode du maximum de vraisemblance

On appelle l‚Äôestimateur du maximum de vraisemblance (EMV) du param√®tre $\theta$, donne l‚Äô√©chantillon r√©alis√© $x$, au $\beta$ tel que

$$
\theta ^*_{\bold x}\text{est EMV de }\theta\iff\theta^*_{\bold x}=\max_{\theta\in\Theta}L(\theta|\bold x)
$$

Bref, on appelle EMV l‚Äôinput $\theta^*$ qui maximise la fonction de vraisemblance $L$ √©tant donn√© un √©chantillon observ√©. **Notons donc, pour toute r√©alisation diff√©rente de l‚Äô√©chantillon, on aura un EMV diff√©rent aussi, donc EMV est une fonction de l‚Äô√©chantillon $\bold x$.** Ceci √©tant dit, je vais juste simplifier sa notation √† $\theta^*$.

Par contre, la d√©finition ci-dessus ne nous garantit ni l‚Äôexistence, ni l‚Äôunicit√© d‚Äôun tel estimateur. Pour trouver l‚Äôinput $\theta$ qui maximise $L$, et supposant que $L$ est deux fois d√©rivable, on calcule $\theta^*$ tel que

$$
\begin{cases}
\frac{\partial L}{\partial\theta}(\theta^*)=0

\\[10pt]

\frac{\partial^2 L}{\partial\theta^2}(\theta^*)<0
\end{cases}
$$

Par contre, le plus souvent c‚Äôest de calculer $\theta^*$ tel que

$$
\begin{cases}
\frac{\partial \ln L}{\partial\theta}(\theta^*)=0
\\[10pt]
\frac{\partial^2 \ln L}{\partial\theta^2}(\theta^*)<0
\end{cases}
$$

**Optimiser $\ln(L)$ est normalement plus simple que $L$. Dans la pratique, on injecte le resultat obtenu de la premi√®re √©quation dans la deuxi√®me**. Rappelons, par ailleurs, que si $Œ∏^*$ est un EMV de $Œ∏$ alors $g(Œ∏^*)$ est l‚ÄôEMV du param√®tre $g(Œ∏)$ pour $g$ continue.

**Exemple**. Supposons qu‚Äôon observe un √©chantillon, et qu‚Äôon s‚Äôint√©resse au param√®tre de la variance, donc $\theta=\text{var}(X)$. On d√©termine un estimateur sans biais de $\theta$, dans ce cas $\hat\theta={S^2}^\prime$. Puis, on calcule $\theta^*$ qui maximise la probabilit√© $L(\theta|x)$ . Finalement, si $g(x)=\sqrt{x}$, donc on a que

$$
g(\theta^*)\text{ est un EMV de }g(\theta)=g(\text{var(X)})=\sqrt{\text{var(X)}}=\sigma_X
$$

**Note**. $g(\hat \theta)$ peut ne pas √™tre sans biais. Notons que $g({S^2}^\prime)=\sqrt{{S^2}^\prime}=S^\prime$ ne peut pas √™tre un estimateur sans biais de $œÉ$, car on aurait alors

$$
\text{var}(S^\prime)=\mathbb {E}[{S^2}^\prime]-\mathbb E^2[S^\prime]=\theta-\theta =0
$$

Et ce qui n‚Äôest pas possible, car $\text{var}(X) >0$ par d√©finition. Contradiction.

### Comportement asymptotique et conditions

Soit $\{\theta^*_n\}$ une suite de $\theta^*$ qui change avec l‚Äôaugmentation de $n$. Donc, les valeurs de cette suite sont telles qu‚Äôelles se distribuent de mani√®re gaussienne quand $n \rightarrow\infin$

$$
\lim_{n\rightarrow\infin} \sqrt{n}(\theta^*_n-\theta)\sim\mathcal N\left(0,\frac{1}{I(\theta)}\right) \iff \lim_{n\rightarrow\infin} \theta^*_n\sim\mathcal N\left(\theta,\frac{1}{nI(\theta)}\right)
$$

C‚Äôest qui est juste une application du th√©or√®me central de la limite, donc on cherche que $n\ge30$. On devra admettre √† nouveau les conditions pour la nullit√© de l‚Äôesp√©rance du score.

Notons que donc $\theta^*_n$ est asymptotiquement sans biais et asymptotiquement efficace, ce qui implique qui $\theta^*_n$ converge en moyenne quadratique (et on pourrait assurer qu‚Äôil converge presque s√ªrement avec d‚Äôautres conditions). Ces propri√©t√©s se r√©sument comme que $\theta^*_n$ est un estimateur BAN : best asymptotically normal.

# Estimation par intervalle de confiance

## Motivation et d√©finition

Un estimateur donne une valeur unique comme estimation. La valeur obtenue a peu de chances de co√Øncider avec celle du vrai param√®tre, qui est inconnu.

L‚Äôestimation par intervalle de confiance consiste a entourer, d‚Äôun intervalle $[a, b]$, la valeur de l‚Äôestimateur et affirmer plut√¥t que $Œ∏$ se trouve dans $[a, b]$. On peut alors choisir $a$ et $b$ de telle sorte que la probabilit√© que cette proposition soit vraie soit assez √©lev√©e.

## Intervalle de confiance pour $\mu$, connaissant $\sigma^2$

<aside>
üí° J‚Äôai jou√© un peu avec la dist. exponentielle pour construire un intervalle de confiance
[https://www.desmos.com/calculator/9kkl96qxre?lang=fr](https://www.desmos.com/calculator/9kkl96qxre?lang=fr)

</aside>

Pour lancer cette estimation de $\mu$, on doit √©tablir deux suppositions :

- La loi/distribution de la population dont on calcul le param√®tre $\mu$ est connue.
La plupart du temps, on suppose qu‚Äôelle est une distribution normale pour pouvoir construire l‚Äôintervalle de confiance.
- La variance $\sigma^2$  est connue.
Par contre, cette supposition n‚Äôest pas r√©aliste. On y retournera apr√®s.

√âtant donn√© qu‚Äôon veut estimer $\mu$ avec $\bar X$, on va calculer un intervalle $[a,b]$ tel que la probabilit√© que $\mu$ soit couverte soit grande, normalement $95\%$.

1. On prend un √©chantillon $X=[X_1,\cdots,X_n]$ d‚Äôo√π on suppose que $X\sim\mathcal N(\mu,\sigma^2)$.
2. On construit notre statistique qui estimerait le param√®tre d‚Äôint√©r√™t $\mu$, dans ce cas $\bar X$.
3. On d√©termine la loi de notre estimateur $\bar X$. On devrait savoir qu‚Äôune somme de $n$ VA normales est aussi une VA normale, particuli√®rement $\bar X \sim (\mu, \frac{\sigma^2}{n})$. Il faudrait calculer ceci *analytiquement* si la loi des $X_i$ de base n‚Äôest pas normale.
4. Une fois d√©termin√©e la loi de $\bar X$, on commence √† se servir de ses propri√©t√©s connues pour √©tablir un intervalle $[a,b]$ tel que 
    
    $$
    \mathbb P(a\le \bar X \le b)=0.95
    $$
    
5. On se sert de la propri√©t√© de la distribution normale suivante. Notons qu‚Äôon peut s‚Äôen servir m√™me si on conna√Æt pas $\mu$.
    
    $$
    \bar X \sim \mathcal N(\mu,\frac{\sigma^2}{n}) \iff\underbrace{\left(\frac{\bar X-\mu}{\sigma/\sqrt n}\right)}_Z\sim\mathcal N(0,1)
    $$
    
6. On change notre direction √† vouloir encadrer $95\%$ de la loi de $z$ sous un nouveau intervalle. Arbitrairement, on voudra que cet intervalle soit sym√©trique autour de $0$, donc
    
    $$
    \mathbb P(-q\le Z\le q)=0.95 \implies q\approx1.96
    $$
    
7. On r√©√©crit l‚Äôin√©galit√© encadrante en termes des param√®tres et l‚Äôestimateur
    
    $$
    \begin{align*}
    &\mathbb P(-q\le Z\le q)
    &\text{Pr√©paration}
    \\[5pt]
    &\mathbb P \left( -1.96 \le \frac{\bar X-\mu}{\sigma/\sqrt n}\le1.96\right)
    &\text{Substitution}
    \\[5pt]
    &\mathbb P \left( -1.96\frac{\sigma}{\sqrt n} \le \bar X-\mu\le1.96\frac{\sigma}{\sqrt n}\right)
    &\text{Mult. par }\frac{\sigma}{\sqrt n}
    \\[5pt]
    &\mathbb P \left(\bar X -1.96\frac{\sigma}{\sqrt n} \le \mu\le\bar X+1.96\frac{\sigma}{\sqrt n}\right)
    &\text{Isolation de }\mu
    \end{align*}
    \\[10pt]
    
    \mathbb P \left(\bar X -1.96\sigma_{\bar X} \le \mu\le\bar X+1.96\sigma_{\bar X}\right)=0.95, \text{ o√π } \sigma_{\bar X}=\frac{\sigma}{\sqrt n}
    $$
    
8. Ici, on peut finalement substituer les valeurs connus de $n$, de $\bar X$ et la valeur de $\sigma$ qui d√©coule de la valeur suppos√©e connue de $\sigma^2$. On obtient une borne num√©rique concr√®te.
9. √âventuellement, si on veut une autre valeur de signification $\alpha$ diff√©rente de $5\%$, la forme g√©n√©rale de l‚ÄôIC est
    
    $$
    \mathbb P \left(\bar X -z_{\alpha/2}\sigma_{\bar X} \le \mu\le\bar X+z_{\alpha/2}\sigma_{\bar X}\right)=\alpha,
    \\[10pt]
    \text{ o√π } z_{\alpha/2}\text{ est telle que }\mathbb P(-z_{\alpha/2}\le Z \le z_{\alpha/2})=1-\alpha
    $$
    

## $\sigma^2$ inconnue et la loi de Student

On avait dit qu‚Äôon suppos√©e connue la valeur de $\sigma^2$, ce qui nous a permis d‚Äô√©tablir l‚ÄôIC. En r√©alit√©, ceci est difficilement le cas. Donc, avant d‚Äôestimer $\mu$ √† travers un IC, on estime $\sigma^2$ avec une estimation ponctuelle, calculant dans ce cas $S^{2^\prime}$ et en le rempla√ßant dans l‚ÄôIC de $\mu$, donc

$$
IC=[\bar X-z_{\alpha/2}\hat\sigma_{\bar X};\bar X+z_{\alpha/2}\hat\sigma_{\bar X}],\text{ o√π } \hat\sigma_{\bar X}=\sqrt{\frac{S^{2^\prime}}{n}}=\frac{S^\prime}{\sqrt n}
$$

Il faut se rappeler que la construction de l‚Äôintervalle de confiance s‚Äôest faite sous l‚Äôhypoth√®se que nous √©chantillonnons une population normale :

$$
Z=\frac{\bar X-\mu}{\sigma_{\bar X}}\sim\mathcal N(0,1)
$$

Mais, si on remplace $\sigma_{\bar X}$ dans la d√©finition de $Z$ par $\hat\sigma_{\bar X}$, notons que le d√©nominateur est maintenant une variable al√©atoire fonction des donn√©es (√† cause de $S^\prime$) et ne plus une constante r√©sultat de deux constantes, et donc **on ne peut pas assurer que $Z$ suit une loi $\mathcal N(0,1)$**. 

Afin de r√©soudre ce probl√®me, on utilisera la loi de Student. La loi de Student √† $k$ degr√©s de libert√©s est la loi du quotient, ind√©pendant, d‚Äôune loi normale centr√©e-r√©duite et de la racine d‚Äôune loi de $œá^2$ divis√© par son degr√© de libert√© $k$.

$$
T=\frac{Z}{\sqrt{U/k}},\hspace{10pt}\text{ o√π }
\begin{cases}
Z=\frac{\bar X-\mu}{\sigma/\sqrt n}=\frac{\bar X-\mu}{\sigma_{\bar X}}
\\[5pt]
U=\sum_{i=1}^kX_i^2\iff U \sim\chi^2_k
\end{cases}
$$

Dans ce cas, le num√©rateur $Z$ reste √©gal et on d√©finit le d√©nominateur comme suit, o√π le facteur $1/\sigma^2$ devant est l‚Äôinverse de la variance de la population, pas de la moyenne √©chantillonnale.

$$
U=\frac{1}{\sigma^2}\underbrace{\sum_{i=1}^n(X_i-\bar X)^2}_{S^{2^\prime}\times(n-1)} \iff \begin{cases}
\frac{U}{n-1}=\frac{S^{2^\prime}}{\sigma^2}
\\[5pt]
U\sim\chi^2_{n-1}
\end{cases}
$$

Finalement, on √©crit la variable al√©atoire de Student $T$ comme suit, o√π $S^\prime$ est la racine carr√©e de la variance √©chantillonnale corrig√©e $S^{2^\prime}$ :

$$
T=

\frac{Z}{\sqrt{U/(n-1)}}
=

\frac{\bar X-\mu}{\underbrace{(\sigma/\sqrt{n})}_{\sigma_{\bar X}}}\times\frac{1}{S^\prime/\sigma}
=
\frac{\bar X-\mu}{S^\prime/\sqrt{n}}

\\[10pt]

\text{Finalement, }
T\sim\mathcal T_{n-1}
$$

Une autre mani√®re de voir $T$ : ‚Äúquotient ind√©pendant d‚Äôune normale avec la racine d‚Äôune loi chi-carr√© divis√©e par ses degr√©s de libert√©s‚Äù. Le degr√©s de libert√©s sont $(n-1)$ car, le fait que la moyenne a √©t√© r√©alis√© est une √©quation que les $X_i$ doivent respecter.

$$
T = \frac{\bar X_n - \mu}{(S_n/\sqrt{n})}=\frac{\frac{\bar X_n-\mu}{\sigma/\sqrt{n}}}{\sqrt{\frac{S_n^2}{\sigma^2}}}=\frac{\mathcal N(0,1)}{\sqrt{\chi^2_{n-1}/(n-1)}}
$$

## Les confusions autour des $\sigma$ et un exemple

Pour clarifier les doutes par rapport √† toutes les notations sur $\sigma$, on suppose une population avec distribution uniforme de $\{1,2,3\}$ et on suppose un √©chantillon de $n=2$. Donc :

- $\sigma$ : param√®tre, l‚Äô√©cart-type de la population, ici $\sigma=\sqrt\frac{2}{3}\approx0.82$.
- $\hat\sigma$ : estimateur, l‚Äô√©cart-type d‚Äôun √©chantillon observ√©.
Si on observe $\{2,3\}$, donc $\hat\sigma = \frac{1}{\sqrt{2}}\approx0.71$.
- $\sigma_{\bar X}$ : param√®tre, l‚Äô√©cart-type de tous les possibles √©chantillons taille $2$.
    - Les possibles √©chantillons (supposant m√™me probabilit√© de les observer) sont $\{1,2\}$, $\{1,3\}$, $\{2,3\}$, donc on en r√©sulte avec une ‚Äúnouvelle population d√©riv√©e‚Äù de $\{1.5, 2, 2.5\}$. En calculant l‚Äô√©cart-type, ici $\sigma_{\bar X}=\frac{1}{\sqrt6}\approx0.41$.
- $\hat\sigma_{\bar X}$ : estimateur, l‚Äô√©cart-type des moyennes √©chantillonnales observ√©es.
    - Si on suppose qu‚Äôon est limit√©s √† observer un seul √©chantillon, disons $\{1,3\}$, donc on finit avec une $\bar X = 2$, et l‚Äôensemble de moyennes √©chantillonnales qu‚Äôon peut observer est juste $\{2\}$. On ne peut pas calculer l‚Äô√©cart-type d‚Äôune seule valeur.
    - On aurait besoin d‚Äôobserver au moins un autre √©chantillon de taille $2$ pour avoir un deuxi√®me valeur de la moyenne √©chantillonnales, disons $2.5$, et puis finalement on pourrait calculer l‚Äô√©cart-type des moyennes √©chantillonnales observ√©es, c√†d. $\{2,2.5\}$, qui serait $\hat\sigma_{\bar X}=\frac{1}{ \sqrt{8}}\approx0.35$.

**Attention**. Parfois c‚Äôest impossible de collecter un autre √©chantillon. Donc, dans ce cas, on peut faire une approximation acceptable si :

- On suppose que les $X_i$ suivent une loi normale (donc $\bar X$ aussi, par propri√©t√© d√©riv√©e de la loi normale), OU
- La taille $n$ de l‚Äô√©chantillon est $n\ge30$ (donc $\bar X$ tend vers une loi normale √† cause du TCL)

Donc, si l‚Äôune de ces deux conditions est v√©rifi√©es, on peut prendre comme estimateur $\hat\sigma_{\bar X}$, qui dans ce cas serait

$$
\hat\sigma_{\bar X}=\frac{\hat\sigma}{\sqrt{n}}=\frac{1/\sqrt{2}}{\sqrt{2}}=0.5
$$

Notons que, si les $X_i$ suivent chacune une loi normal, c‚Äôest strictement vraie l‚Äô√©quation $\sigma_{\bar X} = \frac{\sigma}{\sqrt{n}}$ (sans les chapeaux $\land$ des estimateurs, on parle des vraies param√®tres !), c‚Äôest une d√©rivation alg√©brique.

Par contre, si les $X_i$ suivent une autre loi (dans ce cas une loi uniforme), ce n‚Äôest pas vrai que $\sigma_{\bar X} = \frac{\sigma}{\sqrt{n}}$, c‚Äôest juste une approximation acceptable. La forme serr√©e de $\sigma_{\bar X}$ serait √† calculer analytiquement en termes de $\sigma$ et $n$.

## Statistique pivotale

Une statistique $\varphi([X_i], \theta)$, qui est une fonction des observations $[X_i]_{1\le i\le n}$ et du param√®tre $\theta$, est appel√©e ‚Äúquantit√© pivotale‚Äù si sa distribution ne d√©pend pas du param√®tre inconnu $\theta$.

Par exemple, et supposant $\sigma^2$ connue, la normalisation de la moyenne √©chantillonnale est une statistique pivotale, car sa distribution normalis√©e ne d√©pend pas de $\mu$. Peu importe la valeur de $\mu$, on sait que de prendre une moyenne √©chantillonnale et la normaliser par son $\mu$, quelle que soit, devrait suivre une loi normale standard. 

$$
Z=\varphi([X_i])=\frac{\bar X-\mu}{\sigma_{\bar X}}\sim\mathcal N(0,1)
$$

Dans le cas d‚Äôune distribution exponentielle de param√®tre $\frac{1}{\theta}$, une statistique pivotale est 

$$
\frac{2}{\theta}\sum_{i=1}^nX_i\sim\chi^2_{2n}
$$

C‚Äôest l‚Äôexistence d‚Äôune quantit√© pivotale qui permet la construction d‚Äôun intervalle de confiance. En effet, le fait que la distribution de $œÜ$ ne d√©pend plus du param√®tre inconnu $Œ∏$, **permet de trouver deux nombres $a$ et $b$, ind√©pendants √©galement de $Œ∏$**, tels que 

$$
\mathbb P(a \le \varphi([X_i], \theta)\le b)=1-\alpha
$$

o√π $Œ±$ est un nombre choisi par avance dans $[0, 1]$, normalement tr√®s petit.