# 01 // thÃ©orie de la dÃ©cision en incertitude

[Partie I ThÃ©orie de la dÃ©cision en Incertitude 2022.pdf](ressources/01_theorie_de_la_decision_en_incertitude_partie_i_thorie_de_la_dcision_en_incertitude_2022.pdf)

# Le critÃ¨re de maximisation de lâ€™utilitÃ© espÃ©rÃ©e

## RationalitÃ© en univers certain et â€œincertitudeâ€

On une tuple /{A, U(a)/}, oÃ¹ A est un ensemble dâ€™actions a_i finies et connues, et U(a)/in/R est la fonction dâ€™utilitÃ© associÃ©e Ã  chaque action.

La meilleure action est donc simplement dÃ©finie par a* tel que U(a*) > U(a).

Lâ€™origine de lâ€™incertitude est que lâ€™utilitÃ© dÃ©pend de lâ€™actions mais aussi dâ€™un certain Ã©tat de la nature. ParticuliÃ¨rement, elle se manifeste dans les consÃ©quences de lâ€™action prise.

Il y a deux branches de lâ€™Ã©conomie qui Ã©tudie les acteurs et ses dÃ©cisions :

- ThÃ©orie des jeux : le gain dÃ©pend de lâ€™action propre et de lâ€™action des autres.
- ThÃ©orie de la dÃ©cision en incertain : le gain dÃ©pend de son action dans un certain Ã©tat de la nature.

Il existe une diffÃ©rence entre â€œrisqueâ€ et â€œincertitudeâ€ : 

- Univers risquÃ© : tous les Ã©tats de la nature sont connus en probabilitÃ©.
- Univers incertain : les probabilitÃ©s de rÃ©alisation des Ã©tats futurs ne sont pas connus, voire tous les Ã©tats futurs tout court ne sont pas connus.

Lâ€™approche standard est de ramener les situations dâ€™incertitude Ã  un univers risquÃ© vie les â€œprobabilitÃ©s subjectivesâ€.

## EspÃ©rance et la paradoxe de St. Petesbourg

Face Ã  une disjonctive entre deux situations A et B, un agent veut toujours prendre lâ€™action qui ramÃ¨ne le plus dâ€™utilitÃ©. 

Supposons deux loteries L_1= \{(1000â‚¬, 0.5) ; (-1000â‚¬, 0.5)\} et L_2 = \{(2â‚¬, 0.5) ; (1â‚¬, 0.5) \}. La EMG (espÃ©rance mathÃ©matique de gain) pour L_2 est plus Ã©levÃ©e que celle de L_1. Lâ€™agent choisit donc L_2.

<aside>
ğŸ’¡ Ici, il faut remarquer que les lotos L_1 et L_2 sont elles-mÃªmes des actions a_1 et a_2. En fait, dans ce contexte, chaque action pourrait se voir comme une loterie (le composant alÃ©atoire Ã©tant lâ€™Ã©tat de la nature). Donc, une action se dÃ©crit comme a_i = \{(1â‚¬, 0.5) ; (-1â‚¬, 0.5) \}.

</aside>

Ceci Ã©tant dit, il y a des situations problÃ©matiques si on dÃ©cide de choisir la EMG comme notre critÃ¨re de dÃ©cision. Lâ€™une de ces situations est la paradoxe de St. Petesbourg : câ€™est un jeu dâ€™une piÃ¨ce Ã©quilibrÃ©e lancÃ©e jusquâ€™Ã  lâ€™obtention de lâ€™Ã©vÃ©nement â€œFaceâ€. A chaque jet qui sort pile, le joeur gagne 2^nâ‚¬. Donc :

EMG  = \sum_{n=0}^\infin 2^{-n}2^{n} = 1+1+1â€¦ \to \infin

On dit que le prix juste pour jouer un jeu est Ã©gal Ã  son espÃ©rance. Le problÃ¨me se lÃ¨ve quand lâ€™espÃ©rance est lâ€™infini, personne nâ€™est prÃªte Ã  payer une somme infinie dâ€™argent pour jouer Ã  ce jeu.

La solution proposÃ©e par Bernoulli en 1738 serait que les joueurs maximisent plutÃ´t lâ€™espÃ©rance du logarithme du gain :

V(J) = \sum_{n=0}^\infin 2^{-n} \log(2^{n}) = 2 \log(2)

Et, comme gÃ©nÃ©ralisation de la solution, les joueurs ne maximisent pas les gains monÃ©taires bruts mais lâ€™utilitÃ© que leur procurent ces gains : on remplace la fonction \log par une fonction U(.) croissant concave qui reprÃ©sente lâ€™utilitÃ© de la richesse : 

V(J) = \sum_{n=0}^\infin 2^{-n} U(2^{n})  \text{ avec } Uâ€™(.) > 0, Uâ€™â€™(.) < 0 

## Prise en compte du risque

Jusque lÃ , on a juste considÃ©rÃ© lâ€™espÃ©rance du gain pour choisir entre deux situations. On a pas intÃ©grÃ© la variance dans nos choix. Soient deux loteries L_1 = {(1000â‚¬, 0.5) ; (0â‚¬, 0.5)] et L_2 = {(3000â‚¬, 0.5); (-2000â‚¬, 0.5)}. En espÃ©rance câ€™est le mÃªme, mais L_2 est plus variante que L_1.

Une solution est celle de Markowitz (1952) : intÃ©grer dans lâ€™analyse le risque dont la reprÃ©sentation est la variance des gains. Dâ€™oÃ¹ un double critÃ¨re : lâ€™espÃ©rance de gains et la variance des gains. La valeur V(a) de chaque action est donc une fonction de ces deux paramÃ¨tres.

Par exemple, on pourrait avoir :

V(a) = F(\mu_a, \sigma^2_a) = \alpha + \beta \mu_a - \gamma \sigma^2_a, \text{ avec } Fâ€™_\mu = \beta > 0

Notons que si on fixe une valeur constante de V(a) et on regarde les valeurs \mu et \sigma^2 comme des variables, nous avons une courbe dâ€™indiffÃ©rence.

![Courbe dâ€™indiffÃ©rence pour $V(a)$ fixe](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled.png)

Courbe dâ€™indiffÃ©rence pour $V(a)$ fixÃ©

En plus, on pourrait dÃ©river donc un taux marginal de substitution : 

TMS_{\mu / \sigma^2} = -Fâ€™_{\sigma^2} / Fâ€™_{\mu} = \gamma / \beta

La pente des courbes dâ€™indiffÃ©rence dÃ©pend donc du signe de \gamma : une constante qui mesure le degrÃ© dâ€™aversion au risque.

- Si \gamma > 0 : la pente est positive, la courbe est croissante, et V(a) diminue avec le risque ; lâ€™agent prÃ©sente une â€œaversion au risqueâ€.
- Si \gamma < 0 : la pente est nÃ©gative, la courbe est dÃ©croissante, et V(a) augmente avec le risque ; lâ€™agent prÃ©sente une â€œattirance au risqueâ€.
- Si \gamma = 0 : la pente est nulle, la courbe est constante, et V(a) est indÃ©pendante du risque ; lâ€™agent prÃ©sente une â€œneutralitÃ© au risqueâ€.

![](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled_1.png)

ReprÃ©sentation de courbes dâ€™indiffÃ©rence selon lâ€™attitude au risque
(cas linÃ©aire et non linÃ©aire)

## Le critÃ¨re de lâ€™utilitÃ© espÃ©rÃ©e

### ThÃ©orie de lâ€™UtilitÃ© EspÃ©rÃ©e

Proposer une gÃ©nÃ©ralisation de la solution de Bernoulli sur la base dâ€™un ensemble dâ€™axiomes de comportements : thÃ©orie de lâ€™UtilitÃ© EspÃ©rÃ©e (Von Neumann et Morgenstern, 1947).

Le cadre gÃ©nÃ©rale de cette thÃ©orie est que il existe une tuple /{A, X, P, U(.)/}, oÃ¹ A est lâ€™ensemble dâ€™actions, X est lâ€™ensemble des consÃ©quences et, chaque fois quâ€™on choisit une action, on assigne une probabilitÃ© Ã  chaque consÃ©quence (qui peuvent changer dâ€™une consÃ©quence Ã  lâ€™autre) sous la forme de vecteur, qui sont les Ã©lÃ©ments de P. U(.Â° est une fonction dâ€™utilitÃ© cardinale sur les consÃ©quences.

### Axiomes

Lâ€™objectif de cette thÃ©orie est de, Ã  partir dâ€™une relation de prÃ©fÃ©rence dÃ©finie sur lâ€™ensemble des actions, notÃ©e \ge^\# , construire un isomorphisme entre [A, \ge^\# ] et [\R, \ge] permettant aux agents, sur la base dâ€™un critÃ¨re, dâ€™effectuer un choix en univers incertain.

Pour les relations de prÃ©fÃ©rence, nous avons \ge^\# pour prÃ©fÃ©rence faible, >^\# pour prÃ©fÃ©rence stricte et ~^\# pour lâ€™Ã©quivalence. 

- Axiome 1 : la relation /ge^\# est un prÃ©ordre, câ€™est Ã  dire quâ€™elle est complÃ¨te ($a_1 >^\# a_2$, $a_2 >^\# a_1$ ou $a_1 \sim^\# a_2$) et transitive.
- Axiome 2 : continuitÃ©. Si a_1 /ge^\# a_2 /ge^\# a_3, alors il existe un \lambda \in [0, 1] tel que a_2 \sim^\# [\lambda a_1+(1-\lambda) a\3]
- Axiome 3 : indÃ©pendance. Pour tout a_1, a_2 /in A, a /ge^/# si et seulement si : /alpha a_1 + (1-\alpha) a_3 \ge^\# /alpha a_2 + (1-\alpha) a_3, pour \alpha\in[0,1]

### ThÃ©orÃ¨me de VNM (Von Neumann et Morgenstern)

Si les trois axiomes prÃ©cÃ©dents sont satisfaits, alors il existe une fonction dâ€™utilitÃ© U(.) dÃ©finie sur lâ€™ensemble des consÃ©quences X, Ã  une transformation strictement affine croissante prÃ¨s, et une fonction de valeur V(.) dÃ©finie sur A telles que :

a_1 \ge^\# a_2 \iff V(a_1) = \sum_{i=1}^n p_{1,i}(x_i) u(x_i) \ge \sum_{i=1}^n p_{2,i}(x_i) u(x_i) = V(a_2)

Ainsi, la valeur dâ€™une action risquÃ©e est lâ€™espÃ©rance mathÃ©matique des utilitÃ©s de ses rÃ©sultats possibles (et non plus des gains) : lâ€™individu rationnel prend ses dÃ©cisions en maximisant son utilitÃ© espÃ©rÃ©e.

## Dâ€™autres critÃ¨res de dÃ©cision

### SÃ©curitÃ© dâ€™abord

Ce critÃ¨re choisit lâ€™action parmi toutes que maximise la prÃ©fÃ©rence de Markovitz linÃ©aire, mais en utilisant non pas la variance traditionnelle pais plutÃ´t une variance â€œtronquÃ©eâ€ qui ne prend en compte que les pertes possibles comme suit :

\sigma^2(a) = \sum_{i=1}^n p_a(x_i)^2, x_i < 0

### Maximin

Ceci sâ€™agit de choisir â€œle maximum parmi les minimumsâ€. ParticuliÃ¨rement, il choisi a^* = \max(\min(a_i)). On peut jouer aussi sur lâ€™ordre et la quantitÃ© des \max et des \min comme \min(\max(a_i)) pour trouver le â€œMinimaxâ€ et dâ€™autres critÃ¨res.

### Le critÃ¨re de Hurwicz

Ce critÃ¨re propose une pondÃ©ration des valeurs minimums et maximums dans chaque action : V(a_i) = \alpha \min(a_i) + (1-\alpha) \max(a_i), oÃ¹ \alpha mesure le degrÃ© de pessimisme de lâ€™individu.

### Le critÃ¨re des â€œregretsâ€

Pour chaque Ã©tat de la nature e_i, on regarde lâ€™action qui maximise lâ€™utilitÃ©. Puis, pour chaque action a_i, on calcule la diffÃ©rence de son utilitÃ© rapportÃ©e par rapport Ã  lâ€™utilitÃ© de lâ€™action optimale dans cet Ã©tat. La action Ã  prendre est lâ€™action qui minimise la somme des diffÃ©rences.

![PrÃ©sentation de la situation.](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled_2.png)

PrÃ©sentation de la situation.

![On choisit donc a_1.](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled_3.png)

On choisit donc a_1.

# Le comportement des agents face au risque

## ReprÃ©sentation de la fonction dâ€™utilitÃ© VNM

Soit W un argument qui reprÃ©sente de lâ€™argent ou des ressources. La fonction VNM dâ€™utilitÃ© est positive et concave sous hypothÃ¨se. Soit w_0 une dotation initiale et x_1 et x_2 des consÃ©quences monÃ©taires des actions a_1 et a_2 respectivement. Supposons que p(x_1) = p(x_2) = 1/2.

Notons que si bien on choisit la moitiÃ© entre les deux possibles rÃ©sultats sur nos ressources (50 et 100, donc 75), on est en fait par dessus de la moitiÃ© entre les deux utilitÃ©s rÃ©sultantes. Ceci est consÃ©quence du fait que la fonction est concave.

En fait, si on cherche la moitiÃ© entre les utilitÃ©s rÃ©sultantes, on arrive Ã  que le montant nÃ©cessaire W est infÃ©rieur Ã  75 (en effet, câ€™est 60). Ceci est connu comme lâ€™â€Ã©quivalent certainâ€ ou EC.

Une dÃ©finition plus propre de lâ€™EC est â€œla compensation minimale demandÃ©e par lâ€™agent pour ne pas prendre lâ€™action a ou le prix maximum pour la prendreâ€.â€™

![Note : je pense que le point rouge â€œE[x_a]â€ devrait Ãªtre plutÃ´t â€œE[w_0 + x_a]â€](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/01_theorie_de_la_decision_en_incertitude/untitled_4.png)

Note : je pense que le point rouge â€œE[x_a]â€ devrait Ãªtre plutÃ´t â€œE[w_0 + x_a]â€

Ceci nous permet de crÃ©er une dÃ©finition de comportement par rapport aux risque. Notamment :

- Aversion au risque : EC_a < E[w_0 + x_a]
- NeutralitÃ© au risque : EC_a = E[w_0 + x_a]
- Attirance au risque : EC_a > E[w_0 + x_a]

On peut aussi en dÃ©duire une dÃ©finition diffÃ©rente mais Ã©quivalente Ã  la prÃ©cÃ©dente du fait que U(E[w_0 + x_a]) >E[U(w_0 + x_a)], ce qui caractÃ©rise lâ€™aversion au risque dans cet scÃ©nario.

- Aversion au risque : U(.)^{\partial\partial} < 0
- NeutralitÃ© au risque : U(.)^{\partial\partial} = 0
- Attirance au risque : U(.)^{\partial\partial} > 0

Encore plus, en reprenant lâ€™inÃ©galitÃ© de lâ€™EC, on peut la rÃ©Ã©crire pour dÃ©finir la â€œprime de risqueâ€ :

- Aversion au risque : \pi(w,a) = E[w_0 + x_a] - EC_a > 0
- NeutralitÃ© au risque : \pi(w,a) = E[w_0 + x_a] - EC_a = 0
- Attirance au risque : \pi(w,a) = E[w_0 + x_a] - EC_a < 0

## NÃ©cessitÃ© dâ€™une nouvelle dÃ©finition du risque

Une question Ã  noter : la variance est-elle toujours une bonne mesure du risque (comme câ€™est le cas chez Markovitz) avec le critÃ¨re de lâ€™UtilitÃ© EspÃ©rÃ©e ?

Prenons ce contre-example : X = (1, 10, 100, 1000), a_1 = (0, 0.99, 0, 0.01) et a_2 = (0.8, 0, 0.2, 0). On a donc que E[a*] = 20.8 et E(a) = 19.9; puis \sigma^2(a*) = 1468 < \sigma^2(a) = 9703. Du point de vue (\mu, \sigma^2), a^* domine a. Par contre, si la fonction dâ€™utilitÃ© est U(.) = \log(.), donc E[U(a*)] = 0.4 < E[U(a)] = 1.2.

On cherche donc une dÃ©finition de risque qui soit compatible avec lâ€™utilitÃ© espÃ©rÃ©e. On utilisera la dÃ©finition de Rothschild & Stiglitz (1970). Pour ce faire, on va aligner deux variables alÃ©atoires, a et a^*, par rapport Ã  leur loi de rÃ©partition F et F^*.

On dÃ©finit une relation â€œetre CRMC deâ€¦â€ comme â€œF^* est CRMC de Fâ€, par exemple. Cette relation est vÃ©rifiÃ©e si :

- F* et F ont la mÃªme espÃ©rance
- Soit x_0 un point dans le domaine, donc F*(x) \ge< F(x) pour x \le x_0 et F*(x) \le F(x) pour x \ge x_0.

![A un moment donnÃ©, F* est superÃ©e par f.](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled_5.png)

A un moment donnÃ©, F* est superÃ©e par F.

Si F* est un CRMC de F, alors F* est Â« plus risquÃ©e Â» que F au sens de Rotschild-Stiglitz. Cette dÃ©finition est Ã©quivalente Ã  

- \int_0^x [F*(t) - F(t)]dt pour tout t
- F* et F ont la mÃªme espÃ©rance et, U(.) Ã©tant croissante et concave, donc \int_0^x U(t) dF*(t) \le \int_0^x U(t) dF(t)

Une chose Ã  retenir câ€™est que un plus grand risque (au sens de R&S) implique toujours une plus grande variance, mais pas lâ€™inverse.

Cette dÃ©finition du risque est en relation avec la notion de Dominance Stochastique de second ordre (DS2) : F* est DS2 Ã  F si  [F*(t) - F(t)]dt > 0 pour tout t

![Lâ€™action a* est un CRMC de a, et lâ€™accroissement de risque implique une baisse de lâ€™UE mesurÃ©e par la distance entre E et E*. Cette dÃ©gradation de lâ€™UE est due Ã  la concavitÃ© de u(.).](new/uga/l3/s6/eco/s6_eco_economie_des_contrats/ressources/01_theorie_de_la_decision_en_incertitude_untitled_6.png)

Lâ€™action a* est un CRMC de a, et lâ€™accroissement de risque implique une baisse de lâ€™UE mesurÃ©e par la distance entre E et E*. Cette dÃ©gradation de lâ€™UE est due Ã  la concavitÃ© de U(.).

## Indicateurs dâ€™aversion au risque et comparaisons

Quand peut-on dire quâ€™un agent a une plus forte aversion au risque quâ€™un autre agent ? Le signe de U ={\partial\partial}(.) ne donne que le comportement globale de lâ€™agent face au risque, mais ne â€œmesureâ€ pas le niveau dâ€™aversion ou dâ€™attirance.

### Lâ€™indicateur dâ€™aversion absolue au risque (Arrow & Pratt)

Proposent un indicateur local dâ€™aversion au risque mesurÃ© au niveau de la richesse w de lâ€™agent : r(w) = - U^{\partial\partial}(w) / U^{\partial}(w)

- Si r^\partial(w) > 0, lâ€™avers                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         ion absolue au risque est croissante avec w
- Si r^\partial(w) = 0, lâ€™aversion absolue au risque est constante avec w
- Si r^\partial(w) < 0, lâ€™aversion absolue au risque est dÃ©croissante avec w

### Lâ€™indicateur dâ€™aversion relative au risque (Arrow & Pratt)

Si le risque est multiplicatif (gains et pertes en % de sa richesse initiale), on doit mesurer lâ€™aversion relative au risque par lâ€™indicateur suivant : r*(w) = -wr(w)

- Si {r^*}^\partial(w) > 0, lâ€™aversion relative au risque est croissante avec w
- Si {r^*}^\partial(w) = 0, lâ€™aversion relative au risque est constante avec w
- Si {r^*}^\partial(w) < 0, lâ€™aversion relative au risque est dÃ©croissante avec w

### Le thÃ©orÃ¨me dâ€™Arrow-Pratt

Soient u_i les fonctions dâ€™utilitÃ© des agents i (i=1,2), trois dÃ©finitions Ã©quivalentes de la comparaison de lâ€™aversion au risque peuvent Ãªtre proposÃ©es :

- DÃ©finition 1 : U_1 est plus risque-adverse que U_2 si r_1(w) \ge r_2(w) pour tout w \in X
- DÃ©finition 2 : U_1 est plus risque-adverse que U_2 si \pi_1(w,a) \ge \pi_2(w,a) pour tout a \in A
- DÃ©finition 3 : U_1 est plus risque-adverse que U_2 sâ€™il existe une fonction f(.) concave telle que U_1(w) = f(U_2(w))

# Les limites de lâ€™utilitÃ© espÃ©rÃ©e

## Lâ€™effet de â€œrapport communâ€ (Allais, 1953)

Nombreuses expÃ©riences qui montrent la violation de lâ€™axiome dâ€™indÃ©pendance de la thÃ©orie de lâ€™UE (axiome 3 de VNM).

## Lâ€™effet des â€œconsÃ©quences communesâ€ (Allais, 1953)

## Le paradoxe des croyances de nature probabiliste (Ellsberg, 1961)

## Conclusion