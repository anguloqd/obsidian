# 02 // interactions strat√©giques

[Slides de partie 2.pdf](ressources/02_interactions_strategiques_slides_partie_2_micro2.pdf)

# Th√©orie des jeux non coop√©ratifs

## Introduction

La th√©orie des jeux est tr√®s utilis√©e en √©conomie. Par exemple : comportements des firmes en concurrence imparfaite et environnement concurrentiel, contrats incitatifs (principal et agent, relation d‚Äôemploi‚Ä¶), coordination et incitations au seins d‚Äôune entreprise (jeux d‚Äô√©quipe‚Ä¶).

Ils existent deux grandes branches de th√©ories des jeux :

1. Jeux non-coop√©ratifs
    1. Jeux simultan√©s
    2. Jeux s√©quentiels
2. Jeux coop√©ratifs

Dans ce cours, on va s‚Äôint√©reser aux jeux non-coop√©ratifs √† information compl√®te. Avant d‚Äôy rentrer, on presente un peu de vocabulaire et notions de base.

### Information dans la th√©orie des jeux

Un jeux est dit **√† information compl√®te** si tous les √©l√©ments de la liste qui suit sont connus par tous les joueurs. Elle concerne les jeux simultan√©s et s√©quentiels. Si l‚Äôun de ces √©l√©ments n‚Äôest pas connu par un joueur, le jeux est **√† information incompl√®te**.

- Pr√©f√©rences de joueurs (utilit√©s associ√©s √† chaque r√©sultat)
- Actions disponibles
- Identit√© et nombre des joueurs
- Ordre des d√©cisions

En plus, **et seulement par rapport aux jeux s√©quentiels**, on peut mentionner l‚Äôinformation parfaite ou imparfaite, o√π les joueurs connaissent (ou non) ce que tous les joueurs ont pris comme action toutes les p√©riodes de temps pr√©c√©dentes, respectivement.

### Strat√©gies pures et mixtes

Une strat√©gie pure est un algorithme d√©terministique pour chaque situation o√π le joueur puisse rencontrer. Une strat√©gie mixte est une distribution de probabilit√© sur les actions ou strat√©gies pures.

## Jeux avec d√©cisions simultan√©es

### Repr√©sentation et concepts

Un jeux simultan√© est un jeux o√π les joueurs prennent leurs strat√©gies au m√™me temps et ils ne jouent le jeux qu‚Äôune seule fois. Ils sont repr√©sent√©s sous forme normale (matricielle). Il a trois composants :

- L‚Äôensemble de joueurs : $N = \{1, \dots, n\}$.
- L‚Äôensemble non vide des actions du joueur i : $S_i = \{a_1, \dots, a_m\}$
- La fonction d‚Äôutilit√© pour le joueur $i$ asoci√© √† chaque situation (combinaison d‚Äôactions de tous les joueurs). $u_i(S) : \underbrace{S_1 \times \dots \times S_n}_{S} \mapsto \R$.

Les concepts et vocabulaire de base sont les suivants :

- Action : ce qui le joueur peut jouer. Elles sont contenues dans $S_i$ pour le joueur $i$.
- Strat√©gie : une s√©rie d‚Äôactions qui d√©finit totalement (d√©terministiquement) le comportement du joueur. Elle peut √™tre vue aussi comme un algorithme pour le jeu.
- Gains : les r√©sultats du jeu associ√©s au choix de ces strat√©gies. Ils sont le r√©sultat de la fonction d‚Äôutilit√© $u_i$ pour le joueur $i$.

### Strat√©gies pures et l‚Äô√©quilibre de Nash pure

La strat√©gie pure propose une d√©finition compl√®te du comportement du joueur pour toute situation envisageable. √Ä nouveau, c‚Äôest un algorithme d√©terministique. Une petite note importante c‚Äôest que une strat√©gie peut √™tre aussi prendre une seule action. Dans ce cas, une strat√©gie se confond avec une action, mais normalement ‚Äústrat√©gie‚Äù et ‚Äúaction‚Äù sont diff√©rentes et √† ne pas confondre.

Pour construire un strat√©gie pure, on doit d√©terminer la meilleur strat√©gie pour chaque situation. Une telle mani√®re c‚Äôest la m√©thode d‚Äô√©limination par it√©ration des strat√©gies strictement domin√©es**.**

**√âlimination des strat√©gies domin√©es**. On dit qu‚Äôune strat√©gie $s‚Äô_i$ est *strictement domin√©e* par $s_i$ ****si, les actions des autres constantes, les gains de $i$ sont toujours strictement sup√©rieurs s‚Äôil joue $s_i$ √† la fois de $s‚Äô_i$.

Ayant d√©fini une strat√©gie pure, on peut maintenant parler de **l‚Äô√©quilibre de Nash** pure :

> Un √©quilibre de Nash dans un jeu de deux joueurs est une paire de strat√©gies, chacune √©tant la meilleure r√©ponse √¢ l‚Äôautre.

Plus g√©n√©ralement, un √©quilibre de Nash est une liste de strat√©gies, une par joueur, telle qu‚Äôaucun joueur n‚Äôest incit√© √† changer unilat√©ralement la sienne, en termes d‚Äôam√©lioration de son propre gain.
> 

**Th√©or√®me**. Un √©quilibre atteint utilisant la m√©thode par √©limination des strat√©gies domin√©es est toujours un √©quilibre de Nash. **Par contre, la r√©ciproque est fausse** : ils existent d‚Äô√©quilibres de Nash qui ne sont pas atteints par l‚Äô√©limination des strat√©gies domin√©es. 

On peut rencontrer aussi des strat√©gies *faiblement domin√©es*, o√π les gains de $i$ jouant $s‚Äô_i$ sont au moins aussi importants que s‚Äôil joue $s_i$, les actions des autres constantes.

Quand ils n‚Äôexistent pas des strat√©gies domin√©es, strictement ou faiblement, la m√©thode pr√©sent√©e avant n‚Äôest pas utile pour trouver des √©quilibres de Nash. Ici, on pr√©sente la m√©thode des croissement des meilleures ripostes.

**Croissement des meilleures ripostes**. Une meilleure riposte pour joueur $i$ est la meilleure strat√©gie en fixant une strat√©gie de joueur $i‚Äô$ au pr√©alable (m√™me si le jeux est simultan√©). La croissance de meilleures ripostes est une liste d‚Äôstrat√©gies telle que chaque strat√©gie de chaque joueur est son meilleure riposte aux strat√©gies des autres.

Il se peut qu‚Äôon trouve plus d‚Äôun √©quilibre de Nash, ce qui est totalement valide. On peut raffiner le choix d‚Äô√©quilibre de Nash, c‚Äôest-√†-dire classifier les √©quilibres de Nash :

- √âquilibre pareto-dominant : c‚Äôest l‚Äô√©quilibre de Nash dont la somme d‚Äôutilit√©s de tous les joueurs est la plus grande.
- √âquilibre dominant par le risque : c‚Äôest simplement l‚Äô√©quilibre de Nash qui assure des utilit√©s modeste au pire et de meilleures utilit√©s au mieux, pour chaque joueur.

Ils existent des d√©finitions plus math√©matiques de ces deux raffinements ici : [https://en.wikipedia.org/wiki/Risk_dominance#:~:text=Risk dominance and payoff dominance,Nash equilibria in the game](https://en.wikipedia.org/wiki/Risk_dominance#:~:text=Risk%20dominance%20and%20payoff%20dominance,Nash%20equilibria%20in%20the%20game)

**Point focal**. Ce n‚Äôest pas exactement un √©quilibre de Nash, c‚Äôest une solution que les gens ont tendance √† choisir par d√©faut en l'absence de communication. Elle est faite √† partir du sens commun.

**Note #1**: il est irrel√©vant de classifier un √©quilibre comme dominant par le risque ou pareto-dominant s‚Äôil n‚Äôy a qu‚Äôun seul √©quilibre issue de l‚Äô√©limination de strat√©gies strict. domin√©es.

**Note #2**: aucun jeu √† somme nulle a un equilibre de Nash pure.

**Note #3**: si le prof. n‚Äôexplicite pas de chercher un √©quilibre (mixte), on juste cherche les √©quilibres pures.

### Th√©or√®me de tradition orale

Pensons au dilemme des prisonniers :

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled.png)

Apr√®s avoir analys√©, on sait que le seul √©quilibre de Nash est si les deux prisonniers se d√©noncent, c‚Äôest un √©quilibre qui domine par le risque. On se demande alors si les joueurs pourrait jamais choisir une situation (pas n√©cessairement un √©quilibre !) qui soit efficient au sens de Pareto : o√π on ne peut pas am√©liorer la situation d‚Äôun joueur sans rendre pire la situation d‚Äôun autre.

En fait, il est possible de tomber sur la situation Pareto-efficient o√π les deux se taisent, mais il faudrait jouer le jeux une infinit√© de fois.

Si on jouait le jeu une quantit√© finie de fois connue, √† chaque jeu les prisonniers vont se d√©noncer. Cela dit, si on jouait le jeu √† l'infini et si les joueurs sont ‚Äúsuffisamment patients‚Äù, il existe un √©quilibre de Nash o√π les joueurs se taisent √† chaque fois.

> **Th√©or√®me de tradition orale**. Pour un jeu infiniment r√©p√©t√©, toute strat√©gie qui donne un gain au moins √©gal √† celui qu‚Äôon obtiendrait avec l‚Äô√©quilibre de Nash du jeu de base peut √™tre un √©quilibre possible, si la pr√©f√©rence pour le pr√©sent n‚Äôest pas trop forte.
> 

On mesure la pr√©f√©rence pour le pr√©sent avec un facteur de r√©duction $\delta$ (entre 0 et 1) des utilit√©s des jeux futurs. Si jamais un des joueurs se d√©tourne de la situation pact√©e, l‚Äôautre joueur peut donc jouer son action individuelle minmax en permanence (grim trigger) et l‚Äôutilit√© que le joueur √©go√Øste aurait re√ßu ne sera pas la peine dans le futur, avec l‚Äôinfinit√© des situation qui arrivent.

Ici un lien utile : [https://en.wikipedia.org/wiki/Folk_theorem_(game_theory)#:~:text=In game theory%2C folk theorems,of an infinitely repeated game](https://en.wikipedia.org/wiki/Folk_theorem_(game_theory)#:~:text=In%20game%20theory%2C%20folk%20theorems,of%20an%20infinitely%20repeated%20game).

### Strat√©gies mixtes

Il n‚Äôest pas rare de trouver des jeux o√π il n‚Äôy a pas d‚Äô√©quilibres de Nash. Les jeux √† somme nulles n‚Äôont jamais d‚Äô√©quilibres de Nash. Donc, on a recours aux strat√©gies mixtes. Pour trouver la meilleure strat√©gie mixte, on doit associer une possibilit√© √† chaque strat√©gie.

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_1.png)

Apr√®s, on calcules les utilit√©s esp√©r√©es de Lui et Elle √©tant donn√© qu‚Äôil va au th√©√¢tre $T$ ou au football $F$. Dans ce cas : 

$$
\mathbb{E}[L(T)]=2t+0(1-t) = 2t
\newline
\mathbb{E}[L(F)]=0t+(1-t) = 1-t
\newline
\text{ }
\newline
\mathbb{E}[E(T)]=0q+(1-q) = 1-q
\newline
\mathbb{E}[E(F)]=2q+0(1-q) = 2q
$$

Maintenant, on compare les utilit√©s associ√©s √† chaque action pour chaque joueur. Un joueur va jouer une strat√©gie $i$ pour une certaine probabilit√© associ√© si l‚Äôutilit√© esp√©r√©e √† cette strat√©gie est sup√©rieur aux autres strat√©gies. 

Par exemple, pour lui, l‚Äôutilit√© esp√©r√©e de jouer $T$ est sup√©rieur √† $F$ quand $2t > 1-t$, o√π $t>\frac{1}{3}$. Donc, si on pense rationnellement, il va jouer $T$ si son utilit√© associ√©e est sup√©rieur √† jouer $F$, ce qui d√©pend de si $t>\frac{1}{3}$ ou non. On raisonne similairement pour elle et on arrive √† qu‚Äôelle va jouer $T$ si $q < \frac{1}{3}$ et $F$ sinon.

Un petit d√©tail ce que on construit l‚Äôesp√©rance d‚Äôune action avec les probabilit√©s des actions des autres joueurs, pas avec les probabilit√©s du m√™me joueur !!!

Finalement, on peut construire notre fonction de d√©cision. Une d√©cision est une action avec probabilit√© $1$, c√†d. avec certitude. Pour lui, s‚Äôil sait que $\mathbb{P}(E(T))=t>\frac{1}{3}$, il voudra toujours aller au th√©√¢tre, donc il fixera $q=1$ et $q=0$ sinon. Pareillement pour elle, qui fixera $t=1$ ou $t=0$ si $\mathbb{P}(L(T))=q<\frac{1}{3}$ ou non, respectivement.

On construit alors les fonctions de meilleures d√©cisions pour chaque joueur :

$$
\mathbb{P}(L^*(T))=
\begin{cases}
1, \text{ si } t > \frac{1}{3} \\
0, \text{ si } t < \frac{1}{3}
\end{cases}
\space\space\text{et}\space\space
\mathbb{P}(E^*(T))=
\begin{cases}
1, \text{ si } q < \frac{1}{3} \\
0, \text{ si } q > \frac{1}{3}
\end{cases}
$$

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_2.png)

Les lignes rouges et bleus sont les fonctions de meilleures d√©cisions. Leur point de coupure indiquent un √©quilibre de Nash mixte. Ces fonctions peuvent nous montrer aussi plusieurs √©quilibres, par exemple :

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_3.png)

Mais notons, les √©quilibres √† $(0,0)$ et $(1,1)$ sont d√©cisions pures et d√©terministes, donc elles correspondent √† d‚Äô√©quilibres de Nash pures.

> **Th√©or√®me de Nash**. Tout jeu fini poss√®de au moins un √©quilibre de Nash si les strat√©gies mixtes sont autoris√©es.
> 

Ceci est garanti si et seulement si :

1. L‚Äôensemble de strat√©gies de chaque joueur est convexe et compact,
2. La fonction de paiement de chaque joueur est continue et concave en la
propre strat√©gie du joueur.

## Jeux avec d√©cisions s√©quentielles

### Repr√©sentation et concepts

Un jeu sous forme extensive repr√©sente :

- le nombre de joueurs
- quel joueur joue pour chaque √©tape du jeu
- les actions de chaque joueur
- ce que les joueurs savent au moment o√π ils jouent
- les gains de chaque joueur pour chaque issue possible du jeu

On utilise un arbre de jeu o√π, √† chaque point de d√©cision, il existe un n≈ìud. Le premier n≈ìud au d√©but du jeu s‚Äôappelle le n≈ìud de d√©part, et les n≈ìuds au bas du jeu s‚Äôappellent les n≈ìuds terminaux, chacun contenant les gains des joueurs **par ordre d‚Äôapparition dans le jeu**.

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_4.png)

Dans ce type de jeux, il est important de mentionner la notion d‚Äôinformation parfaite et imparfaite. L‚Äôinformation est parfaite quand chaque joueur conna√Æt les actions pr√©c√©dentes de toutes les p√©riodes de temps pr√©c√©dentes pour tous les joueurs.

Si on parle d‚Äôinformation imparfaite en jeux s√©quentiels, il faut parler de l‚Äôensemble d‚Äôinformations, qui est l‚Äôensemble de n≈ìuds o√π le m√™me joueur joue et o√π il ne sait pas √† quel n≈ìud particulier il se trouve. Dans l‚Äôimage pr√©c√©dente, l‚Äôensemble d‚Äôinformation de J2 sont ses deux n≈ìuds, supposons qu‚Äôil sait pas ce que J1 a jou√©.

Tout jeu sous forme extensive peut s‚Äô√©crire sous forme normale si toutes les strat√©gies possibles de joueurs sont sp√©cifi√©es de mani√®re suffisamment exhaustive, **il faut que ce soit en information imparfaite pourque √ßa puisse simuler un jeux de d√©cisions simultan√©es**.

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_5.png)

[Deriving Normal Form from Extensive Form Games.pdf](ressources/02_interactions_strategiques_deriving_normal_form_from_extensive_form_games.pdf)

### L‚Äô√©quilibre de Nash parfait en sous-jeux

Avant d‚Äôintroduire cette notion d‚Äô√©quilibre, il faut d√©finir ce qui est un sous-jeu : c‚Äôest simplement un ensemble compos√© d‚Äôun n≈ìud et tous les n≈ìuds qui le succ√®dent. Le jeux m√™me est un sous-jeu de lui-m√™me.

Apr√®s, on peut parler de l‚Äôinduction √† rebours : c‚Äôest une m√©thode pour trouver d‚Äô√©quilibres de Nash d‚Äôun jeu s√©quentiel. On commence par les √©tats finaux ou n≈ìud terminaux du jeu et on monte et passe par chaque sous-jeu r√©cursivement vers le n≈ìud initial. √Ä chaque n≈ìud, on determine l‚Äôaction optimale du joueur qui joue.

L‚Äô√©quilibre qui sort de cette m√©thode est appel√© ***√©quilibre parfait en sous-jeu***. Formellement, est une combinaison de strat√©gies telle que les actions prescrites par ces strat√©gies constituent un √©quilibre de Nash dans tous les sous-jeux.

![Avec l‚Äôinduction √† rebours, l‚Äô√©quilibre parfait en sous-jeu est {Dp, tl}.](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_6.png)

Avec l‚Äôinduction √† rebours, l‚Äô√©quilibre parfait en sous-jeu est {Dp, TL}.

Note #1 : Un √©quilibre parfait en sous-jeu est un √©quilibre de Nash. **Reciproque fausse**.

Note #2 : dans les jeux simultan√©es, un √©quilibre de Nash pure √©tait un ensemble avec **juste une action** pour chaque joueur. Ici, est une **liste de actions** pour chaque joueur.

### Applications : menace cr√©dible et engagement strat√©gique

Supposons qu‚Äôils existent les joueurs A et B. A communique √† B que son comportement m√®nera une r√©ponse de la part de A. Si telle r√©ponse est un net positif, est un engagement. Sinon, est une *bluff*. Une menace est cr√©dible si la r√©ponse est un net positif, et non-cr√©dible sinon. Cette d√©finition est celle de Schelling.

Particuli√®rement, une menace non-cr√©dible est faite avec l‚Äôespoir de ne pas l‚Äô√©x√©cuter, car elle serait p√©nalisante.

Dans le graphique d‚Äôun jeu s√©quentiel, pour que une menace soit cr√©dible dans un √©quilibre, √† chaque n≈ìud ou on peut ex√©cuter la menace, on l‚Äô√©x√©cute.

![Le rouge est un √©quilibre parfait de sous-jeu, tant que le bleu est un √©quilibre de Nash tout court.](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_7.png)

Le rouge est un √©quilibre parfait de sous-jeu, tant que le bleu est un √©quilibre de Nash tout court.

# L‚Äôoligopole non coop√©ratif

<aside>
üí° Une firme dans ce contexte d‚Äôoligopole est cens√©e de vouloir toujours maximiser le profit math√©matiquement. Les crit√®res de gestion alternative comme la gestion √† l‚Äô√©quilibre n‚Äôexiste plus ici. On est dans le contexte de th√©orie de jeux.

</aside>

## Duopole de Cournot (concurrence par la $q$, simultan√©)

<aside>
üí° Un exo de Cournot √† l‚Äôexamen prend 10 minutes, maximum 15 minutes.

</aside>

### Description et hypoth√®ses du mod√®le

- Deux firmes produisent un bien homog√®ne en quantit√©s $q_1$ et $q_2$, respectivement.
- Leur fonctions de co√ªt total sont identiques : $C_1(q_1) = C_2(q_2)$.
- La production totale de l‚Äô√©conomie est la sommes des quantit√©s : $q = q_1+q_2$.
- La demande est atomique : $p=p(q)=p(q_1+q_2)$
- La variable strat√©gique est la quantit√© et non pas le prix.
- Les firmes veulent maximiser son profit.
- **Variation conjecturale** : chaque firme fait une conjecture sur la production de son concurrent en r√©action √† sa production propre, puis elle corrige sa production.

Comme conclusion du mod√®le, l‚Äô√©quilibre de duopole atteint nous m√®ne √† des prix, quantit√©s et profit interm√©diaires entre le prix de monopole et le prix concurrentiel.

En termes d‚Äôefficacit√©, il est pr√©f√©rable pour les consommateurs d‚Äôavoir un duopole √† la Cournot sur un monopole, tant que pour les firmes il serait mieux d‚Äôagir comme un monopole (oligopole coop√©ratif, o√π deux firmes sous une entente).

### L‚Äô√©quilibre de Cournot-Nash

L‚Äô√©quilibre des quantit√©s produites est d√©duit en appliquant la condition d‚Äôoptimisation de premier ordre des profits de chaque firme.

$$
\text{Profit de }i : \pi_i(q_i+q_j)=p(q_i+q_j)\times q_i -C(q_i)

\\
\text{}
\\

\text{CPO} : \frac{\partial \pi_i}{\partial q_i} = 0 \iff \frac{\partial p(q_i+q_j)}{\partial q_i}q_i + p(q_i+q_j) - \frac{\partial C(q_i)}{\partial q_i} =0
$$

La fonction qui resulte d‚Äôappliquer la CPO, et isolant $q_i$ d‚Äôun seul c√¥t√©, au profit de la firme $i$ est la **fonction de r√©action de la firme $i$**. **Notons qu‚Äôelle prend comme argument la quantit√© de l‚Äôautre firme !**

$$
q_i = R_i(q_j)= \frac{1}{\partial p/\partial q_i}\left(\frac{\partial C}{\partial q_i} -  p(q_i+q_j) \right)
$$

L‚Äô√©quilibre est donc le pair de quantit√©s qui satisfait le syst√®me d‚Äô√©quations ci-dessous :

$$
\left.
\begin{array}{l}
q_i=R_i(q_j)
\\
q_j=R_j(q_i)
\end{array}
\right\} \implies 
\begin{array}{l}
q_i^* = R_i(R_j(q_i)) \\
q_j^* = R_j(R_i(q_j))
\end{array}
$$

Cet √©quilibre $(q_i^*,q_j^*)$ est un √©quilibre de Cournot-Nash. Il correspond √† l‚Äôintersection des fonctions de r√©action.

### Analyse graphique

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_8.png)

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_9.png)

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_10.png)

### Repr√©sentation sous forme normale

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_11.png)

Si l‚Äô√©quilibre de Nash trouver n‚Äôest pas celui trouv√©e par le syst√®me d‚Äô√©quation, **on a un erreur**. Il peut avoir deux sources d‚Äôerreur : erreur dans le calculs des $q$ d‚Äôequilibre, ou erreur dans le calculs des profits $\pi$.

**Note practique** : toute strat√©gie hors d‚Äô√©quilibre en Cournot est strictement domin√©e, √† la hausse et √† la baisse.

## Duopole de Stackelberg (concurrence par la $q$, s√©quentiel)

### Description et hypoth√®se du mod√®le

Les hypoth√®ses restent presque les m√™mes en comparaison au duopole de Cournot, √† exception que ce jeu est s√©quentiel et non pas simultan√©. Particuli√®rement, l‚Äôhypoth√®se de s√©quentialit√© est √©nonc√©e comme suit :

- La firme *leader* a une information compl√®te sur la courbe de r√©action de l‚Äôautre
firme. La firme *follower* cherchera √† maximiser son profit compte-tenu de la situation qui a √©t√© cr√©√©e par la firme leader.

### D√©termination de l‚Äô√©quilibre

Le leader choisira la quantit√© que maximise son profit, supposant qu‚Äôil conna√Æt la quantit√© de r√©action du follower. Donc, en comparaison avec Cournot, la firme follower maintient sa fonction de r√©action (le follower accepte la quantit√© du leader comme constante), tant que le leader utilise la fonction de r√©action du follower dans sa propre r√©action.

$$
\text{Cournot : }\frac{\partial p(q_1+q_2)}{\partial q_1}q_1 + p(q_1+q_1) - \frac{\partial C(q_1)}{\partial q_1} =0
\\
\text{}
\\
\text{Stackelberg } : \frac{\partial p(q_1+R_2(q_1))}{\partial q_1} q_1 + p(q_1+R_2(q_1)) - \frac{\partial C(q_1)}{q_1} =0
$$

Le crit√®re de r√©action de la firme leader sera le $q$ qui maximise le profit, qui est-ce qui est exprim√© en haut. Notons qu‚Äôon ne parle plus d‚Äôune fonction de r√©action du leader.

### Analyse graphique

Pour repr√©senter l‚Äô√©quilibre sur un graphique, il faudrait aussi repr√©senter des courbes *isoprofits*. Ce sont des courbes qui repr√©sentent un m√™me profit \pi pour toute combinaison de q_1 et q_2 qui l‚Äôatteignent.

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_12.png)

Plus inf√©rieure est la position de l‚Äôisoprofit, plus grand est le profit qu‚Äôelle repr√©sente. Pour chaque niveau de production de $q_2$, on trace une ligne horizontale qui coupe quelque courbe d‚Äôisoprofit forc√©ment dans son sommet. Ce point-l√† correspond √† la quantit√© $q_1$ que le leader doit produire pour maximiser son profit.

D‚Äôautre mani√®re, pour le $q_1$ de chaque sommet d‚Äôisoprofit, il existe un $q_2$ duquel produire $q_1$ atteint le profit maximum.

![Notons que le sommet est aussi o√π la droite tangente est constante.](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_13.png)

Notons que le sommet est aussi o√π la droite tangente est constante.

Quand le leader maximise son profit, il conna√Æt la fonction de r√©action de la firme follower. Il commencera √† descendre d‚Äôisoprofit en isoprofit jusqu‚Äô√† arriver √† la derni√®re isoprofit qui touche la fonction de r√©action du follower. Ce courbe-la est le profit maximum, et son point de coupure avec $R_2$ contient le $q_2$ qui maximise le profit.

![**LE POINT OU $R_1 = R_2$ EST L‚Äô√âQUILIBRE DE COURNOT. DONC $\pi^\text{Stack}_1 > \pi_1^\text{cournot}$.**](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_14.png)

**LE POINT OU $R_1 = R_2$ EST L‚Äô√âQUILIBRE DE COURNOT. DONC $\pi^\text{Stack}_1 > \pi_1^\text{Cournot}$.**

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_15.png)

Conclusions :

- Le suiveur produit moins que chez Cournot, le leader produit plus que chez Cournot.
- La $q$ du leader est plus grande que la $q$ du follower.

### Repr√©sentation sous forme extensive

![untitled](new/uga/l2/s3/eco/s3_eco_microeconomie_2/ressources/02_interactions_strategiques_untitled_16.png)

- L‚Äô√©quilibre de Stackelberg est l‚Äô√©quilibre de Nash parfait en sous-jeu.

## Duopole de Bertrand (concurrence par le $\$$, simultan√©)

### Description et hypoth√®ses de base

Hypoth√®ses ‚Äú√©videntes‚Äù :

- La firme cherche √† maximiser son profit.
- Le bien produit est parfaitement homog√®ne.
- Les firmes ont la capacit√© de production pour fournir la totalit√© du march√©.

Hypoth√®ses plus importantes : 

- La variable strat√©gique de chacune des firme sur le march√© est le **prix**.
- La demande assum√©e par chaque firme d√©pend de son niveau de prix par rapport √† l‚Äôautre firme. Particuli√®rement, pour la firme $i$, sa quantit√© demand√©e est :
    
    $$
    D_i(p_1,p_2)=
    \begin{cases}
    D(p_i), \text{ si } p_i<p_j \\
    \frac{D(p)}{2}, \text{ si } p_i=p_j=p \\
    0, \text{ si } p_i>p_j
    \end{cases}
    $$
    

### D√©termination de l‚Äô√©quilibre

> **Th√©or√®me de Bertrand**. Sous les 5 derniers hypoth√®ses, le seule √©quilibre de prix est $p_1^*=p_2^*=Cm$.
> 

Mais notons, $p=Cm$ est la condition d‚Äô√©quilibre d‚Äôun march√© concurrentiel, donc l‚Äô√©quilibre est celui de la concurrence parfaite. Encore plus, **on suppose que $Cm$ est constante !**

La **paradoxe de Bertrand** est que, alors qu‚Äôelles sont deux, les entreprises agissent
comme si elles √©taient un nombre infini. Elles se comportent ainsi conform√©ment √† l‚Äôhypoth√®se d‚Äôatomicit√© de la concurrence parfaite.

L‚Äô√©quilibre de Bertrand, comme l‚Äô√©quilibre de Cournot, est un √©quilibre de Nash.

On arrive math√©matiquement √† que $Cm$ est le prix d‚Äô√©quilibre si on cherche les prix de $i$ (resp. $j$) qui maximise son profit respectif. **Celle-ci est aussi la fonction de r√©action**. C‚Äôest-√†-dire :

$$
R_i(p_j)=p_i^*=\argmax_{p_i} \pi_i(p_i,p_j), \text{ o√π } \pi_i(p_i,p_j)= \overbrace{(p_i-Cm)}^{\text{ Revenu moyen}} \times D_i(p_i,p_j)
$$

### Conclusion

On note que si $p_i=c$, donc $p_i-c=0$, donc si le revenu moyen de chaque unit√© vendue est $0$, le profit $\pi_i$ est aussi $0$, donc l‚Äô√©quilibre de Bertrand correspond √† l'optimum social (√©quilibre de concurrence). Il est donc pr√©f√©rable pour les consommateurs sur les duopoles de Cournot et Stackelberg.

**Le r√©sultat de Bertrand d√©pend de plusieurs hypoth√®ses tr√®s restrictives.** 

Particuli√®rement, il se peut qu‚Äôil soit plus profitable pour une entreprise A de n‚Äôest pas concurrir par le prix si son concurrent ne peut pas couvrir toute la demande de march√© avec sa production.