# 02 // mÃ©thodes de statistiques infÃ©rentielles

Date de crÃ©ation: March 24, 2023 1:50 AM
ModifiÃ©: November 13, 2023 11:49 PM

[Slides de mÃ©thodes de stats infÃ©rentielles](slides_mthodes_stat_inf_annote.pdf)

# Intervalle de confiance

## Motivation

Au croisement des statistiques et des probabilitÃ©s, la dÃ©marche des statistiques infÃ©rentielles est de considÃ©rer lâ€™observation $(x_1, \dots , x_d)$  comme la rÃ©alisation de $d$ rÃ©pÃ©titions $(X_1, \dots , X_d)$ dâ€™une expÃ©rience alÃ©atoire $X$.

La rÃ©alitÃ© est souvent entachÃ©e dâ€™erreur. Cette dÃ©marche permet dâ€™en tenir compte, dâ€™imaginer, dâ€™infÃ©rer le problÃ¨me pur, et de travailler pour mieux comprendre lâ€™erreur.

## Ã‰chantillon

On considÃ¨re une suite de variables alÃ©atoires $(X_i)_{iâˆˆ\N}$ identiques et indÃ©pendantes. Un Ã©chantillon de taille $d$ est lâ€™ensemble des variables $(X_1, \dots, X_d)$. Une rÃ©alisation de cet Ã©chantillon est lâ€™observation $(x_1, \dots, x_d)$. On travaillera alors sous la condition $(X_1 = x_1, \dots, X_d = x_d)$.

## Estimation

On cherche a connaÃ®tre un paramÃ¨tre $Î¸$ qui dÃ©pend de la loi de $X$ (par exemple son espÃ©rance ou sa variance). On rÃ©plique $n$ fois $X$ de maniÃ¨re indÃ©pendante $(X_1, \dots ,X_n)$. On Ã©value alors $Î¸$ par $\hat{Î¸} = \hat{Î¸}_n$ grÃ¢ce aux rÃ©alisations possibles $(x_1, \dots , x_n)$ de lâ€™Ã©chantillon a $n$ Ã©lÃ©ments. La valeur $\hat{Î¸}_n$ est nommÃ©e estimÃ© ou estimation ponctuelle.

On prendra par exemple $\hat{Î¸}_n = \sum_i x_i/n$ pour estimer la moyenne de $X$, ou $\hat{Ïƒ} = \sum_i (x_i âˆ’ \hat{Î¸}_n)^2/(n âˆ’ 1)$ pour estimer la variance.

Pour rÃ©capituler, le paramÃ¨tre rÃ©el constant inconnu est $Î¸$. Il est approchÃ© par lâ€™estimateur $Î¸_n =
f(X_1, \dots, X_n)$, variable alÃ©atoire, estimÃ© grÃ¢ce au relevÃ© statistique par $\hat{Î¸} = \hat{Î¸}_n = f(x_1, \dots, x_n)$. On note parfois comme suit :

$$
\hat{\theta}_n=E[\theta_n|X_1=x_1, \dots, X_n=x_n]
$$

<aside>
ğŸ’¡ **Note de la variance estimÃ©e**. La variance est une moyenne des Ã©carts (au carrÃ©). Dans un Ã©chantillon de taille $n$, il y a $n-1$ Ã©carts.

</aside>

## Estimation par intervalle de confiance

On cherche Ã  encadrer une V.A. ou une statistique dans un intervalle $[p,q]$ telle que la probabilitÃ© que la statistique appartienne Ã  cet intervalle soit 95% (et donc 5% de risque). On veut donc dÃ©terminer $p$ et $q$. Ici, $f_n$ est notre statistique est câ€™est une fonction de la loi de $X$.

$$
P(\underbrace{\mu_n âˆ’ aÏƒ_n}_p â‰¤ f_n â‰¤ \underbrace{\mu_n + aÏƒ_n}_q) = 0.95
$$

On admettra que $a = 1.96$ si notre intervalle de confiance est de $95\%.$

Pour dÃ©terminer finalement les valeurs de $p$ et $q$, on calcule $\mu_n=E[f_n]$ et $\sigma_n =\sqrt{Var(f_n)}$ utilisant la dÃ©finition de la statistique $f_n$ en termes de $X$ et $n$. Une fois on a des valeurs concrÃ¨tes de $X$ et $n$, et donc une valeur de $f_n$, on peut estimer $\mu_n$ et $\sigma_n$. **Finalement, on pourra calculer $p$ et $q$**.

# Intervalle de fluctuation

## Tracer de limites aux biais

Lâ€™intervalle de fluctuation est lâ€™intervalle qui nous permet de prendre une dÃ©cision en fonction de si la valeur rÃ©alisÃ© de notre statistique se retrouve dans lâ€™intervalle ou non. Ã€ $5\%$ de risque, lâ€™intervalle est :

$$
[\mu-2\sigma, \mu+2\sigma]
$$

Note : rÃ©ellement, le $2$ est remplacÃ© pour un $1.96$.

Si la statistique se retrouve dehors de lâ€™intervalle, on dira quâ€™on ne peut pas le faire confiance et quâ€™elle est biaisÃ©e.

<aside>
ğŸ’¡ Par contre, si la statistique est dans lâ€™intervalle, on ne peut pas dire que on peut le faire confiance ! **On dit juste que *rien sâ€™oppose au fait* quâ€™elle soit Ã©quilibrÃ©e**.

Une piÃ¨ce qui montre 58% des fois rÃ©alisÃ©es des piles se trouve dans lâ€™intervalle de confiance dâ€™une piÃ¨ce qui montre en moyenne une pile 50% des fois, mais aussi si elle montre des pile 60% des fois (une piÃ¨ce non-Ã©quilibrÃ©e quoi) !

</aside>

Notons quâ€™ici, on utilise les paramÃ¨tre thÃ©oriques ou non pas des estimations ponctuelles comme on la fait dans la section prÃ©cÃ©dente !

# Introduction aux tests statistiques

## Lâ€™idÃ©e

On veut savoir si une proposition est vraie ou fausse ayant un morceau dâ€™â€Ã©videnceâ€, qui est une observation ou Ã©chantillon tirÃ© dâ€™un processus alÃ©atoire. Normalement, cette proposition est sur un paramÃ¨tre de ce processus alÃ©atoire.

On dÃ©cidera si on accepte ou non la proposition comme si câ€™Ã©tait une preuve par contradiction. Soit $P$ la proposition quâ€™on veut dÃ©montrer, donc on cherchera Ã  montrer que $\lnot P$ est fausse et donc que $P$ est vraie. La nÃ©gation de $P$ reÃ§oit le nom de â€œhypothÃ¨se nulleâ€ et on la note $\mathcal{H}_0$.

La maniÃ¨re de dire si $\mathcal{H}_0$ est vraie ou fausse est dÃ©terminant la probabilitÃ© dâ€™observer lâ€™Ã©chantillon rÃ©alisÃ©. Si la probabilitÃ© est trÃ¨s petite (normalement on fixe cette probabilitÃ© comme $5\%$), il est trÃ¨s peu probable que $\mathcal{H}_0$ soit vraie, et donc on la rejette, ce qui signifie quâ€™on accepte sa proposition contraire $P$.

On aura besoin de formuler une autre hypothÃ¨se quand on aura rejetÃ© $\mathcal{H}_0$, qui sâ€™appellera lâ€™hypothÃ¨se alternative $\mathcal{H}_1$. On notera que les hypothÃ¨ses ne sont pas nÃ©cessairement le contraire lâ€™une de lâ€™autre, et donc $\mathcal{H}_1$ nâ€™est pas exactement $P$.

Il se peut aussi quâ€™on rejette $\mathcal{H}_0$ quand elle est vraie, ou quâ€™on Ã©choue Ã  la rejeter quand elle est fausse. Ces deux erreur sont des erreurs de premiÃ¨re et deuxiÃ¨me espÃ¨ce, respectivement.

|  | $\mathcal{H}_0$ est fausse | $\mathcal{H}_0$ est vraie |
| --- | --- | --- |
| Rejeter $\mathcal{H}_0$ | OK | Erreur de Type I |
| Ã‰chouer Ã  rejeter $\mathcal{H}_0$ | Erreur de Type II | OK |

On notera Î± la probabilitÃ© dâ€™erreur de premiÃ¨re espÃ¨ce, appelÃ©e parfois *seuil*. On prendra en gÃ©nÃ©ral pour $Î±$ les valeurs $0.01$, $0.05$ ou $0.1$. Il est a noter que mÃ©caniquement, si lâ€™erreur de premiÃ¨re espÃ¨ce baisse, lâ€™erreur de seconde espÃ¨ce augmente.

## La variable ou statistique du test

On fixe la dÃ©finition de la statistique qui nous intÃ©resse. Elle est basÃ©e sur lâ€™Ã©chantillon observÃ©. Par exemple, la statistique peut Ãªtre simplement la proportion de piles sur $20$ lancÃ©es.

## Zone de rejet et dÃ©cision

Ayant dÃ©finie la statistique, on se demande quelle est la probabilitÃ© quâ€™on ait observÃ© la valeur rÃ©alisÃ©e de cette statistique, appelÃ©e $*p$-value*. Si la valeur est $5\%$ ou moins, on rejette $\mathcal{H}_0$, car on se dit quâ€™il est trÃ¨s peu probable quâ€™on ait observÃ© la valeur de la statistique seulement par hasard et quâ€™il doit avoir une autre raison (qui est capturÃ©e par $\mathcal{H}_1$).

## Discussion

On peut faire plusieurs remarques sur ce que lâ€™on ressent Ã  propos du test 

- Plus lâ€™Ã©chantillon est petit, plus le test est laxiste, mais cela peut-Ãªtre lâ€™inverse.
- La dÃ©marche semble plus robuste si lâ€™on cherche a rejeter lâ€™hypothÃ¨se $\mathcal{H}_0$ par analogie avec un raisonnement par lâ€™absurde. (Test au sens de Fisher).
- On est tributaire du hasard dans le tirage de lâ€™Ã©chantillon. En effet, les tests ont Ã©tÃ© crÃ©Ã©s dans le contexte de la qualitÃ© dâ€™une production, ou lâ€™Ã©chantillonnage est reproductible et ou on acceptera de jeter une production Ã  tort si on peut sauver dâ€™avantage de sÃ©ries produites.

Pour toutes ces raisons, les tests ne restent quâ€™une aide Ã  la dÃ©cision, mÃªme sâ€™ils sont largement utilisÃ©s dans tous les domaines scientifiques (sciences humaines, technologiques, Ã©conomiques...). 

Enfin, en toute rigueur mathÃ©matique, le non rejet de lâ€™hypothÃ¨se nulle ne vaut pas acceptation, mais nous permet juste de dire que rien ne sâ€™oppose a $\mathcal{H}_0$. On renvoie Ã  la discussion dans lâ€™intervalle de fluctuation.