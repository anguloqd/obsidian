# 03 // th√©orie des graphes

# Introduction

[Slides de th√©orie de graphes](slides_graphes_minfo_annote2.pdf)

## D√©finition intuitive et formelle d‚Äôun graphe (orient√©)

On introduit le concept d‚Äôun graphe avec un exemple : un site internet est compos√© de cinq pages not√©es $A$, $B$, $C$, $D$ et $E$. En un clic, on peut passer d‚Äôune page √† certaines autres selon les possibilit√©s suivantes.

- De la page $A$, on peut passer en un clic aux pages $C$ et $E$.
- De la page $B$, on peut passer aux pages $A$ et $D$.
- Depuis la page $C$, on peut acc√©der √† la page $B$ ou rester sur $C$.
- Quand on est sur la page $D$, on peut seulement aller sur la page $C$ et de la page $E$, on ne peut aller que sur la page $A$.

![Graphique sagittal.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled.png)

Graphique sagittal.

Un graphe est une tuple $G=\{V,E\}$. Les points ou n≈ìuds sont appel√©s des *sommets* et son ensemble est not√© $V$, et les fl√®ches orient√©s sont appel√©es des *arcs* et son ensemble est $*E*$. 

Par rapport √† la notation, les sommets sont simplement not√©s avec de lettres comme $V=\{a_0, a_1, \dots, a_n\}$, tant que les arcs sont not√©s comme des couples de $E$ comme $E=\{(a_1,a_2),(a_3,a_5),(a_7,a_{11})\}$ pour dire qu‚Äôil existe un arc qui part du sommet $a_3$ pour arriver au sommet $a_5$, par exemple.

# Matrice d‚Äôadjacence

## D√©finition et exemple

Pour formaliser une certaine configuration de sommets et d‚Äôarcs d‚Äôun graphe $G$, on utilise une matrice dite *d‚Äôadjacence*. Cette matrice compte les chemins allant du sommet en ligne au sommet en colonne.

Pour le graphe pr√©c√©dent, on obtient cette matrice d‚Äôadjacence :

![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_1.png)

$$
M_G=\begin{bmatrix}
0&0&1&0&1\\
1&0&0&1&0\\
0&1&1&0&0\\
0&0&1&0&0\\
1&0&0&0&0
\end{bmatrix}
$$

Si on ajoutait un autre chemin allant de $D$ √† $C$, on changerait l‚Äôentr√©e $(4,3)$ √† $2$ pour compter le total des chemins.

On peut d√©finir aussi les ensembles de successeurs et de pr√©d√©cesseurs d‚Äôun sommet donn√©. Pour $A$, on note ses successeurs $\Gamma^+(A)=\{C,E\}$ et ses pr√©d√©cesseurs $\Gamma^-(A)=\{B,E\}$.

## Chemin et longueur dans un graphe orient√©

Un chemin est d√©fini formellement comme une suite de sommets tel qu‚Äôun tout sommet est successeur du sommet pr√©c√©dent, √† exception du premier sommet.

$$
\text{Il y a un chemin }v_a\text{-}v_z \text{ de longueur }n-1 \iff \exists(\{v_i\}_{i=0}^n): \\
v_i\in V,(v_i,v_{i+1})\in E, v_0=v_a, v_n=v_z
$$

- Un chemin √©l√©mentaire ne passe pas deux fois par un m√™me sommet.
    - Un chemin *hamiltonien* passe une seule fois par tous les sommets du graphe.
- Un chemin simple ne passe deux fois par un m√™me arc.
- Un *circuit* est un chemin dont le sommet de d√©part et d‚Äôarriv√© sont le m√™me sommet.

<aside>
‚ùó Comme cons√©quence de cette d√©finition, **il existe toujours un chemin de longueur $0$ d‚Äôun sommet √† lui-m√™me, sans besoin de le connecter √† lui-m√™me avec un arc**.

Pour un graphe avec un seule sommet connect√© √† lui-m√™me, le chemin de longueur plus courte est $0$, c√†d. de ne pas bouger du sommet. La chemin de ce sommet √† lui-m√™me passant par la boucle est de longueur $1$.

![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_2.png)

</aside>

Notons d√©j√† qu‚Äôun chemin de longueur $1$ est tout simplement un arc, qui sont not√©s dans la matrice d‚Äôadjancence. Deux sommets sont *adjacents* s‚Äôil sont connect√©s par un arc. Une propri√©t√© int√©ressante de telle matrice est qu‚Äôon peut en d√©duire les chemins de longueur $n$ g√©n√©rale avec l‚Äôop√©ration $M^n$. 

![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_1.png)

$$
M=\begin{bmatrix}
0&0&1&0&1\\
1&0&0&1&0\\
0&1&1&0&0\\
0&0&1&0&0\\
1&0&0&0&0
\end{bmatrix}\\
\text{}\\
M^2=\begin{bmatrix}
1&1&1&0&1\\
0&0&2&0&1\\
1&1&1&1&0\\
0&1&1&0&0\\
0&0&1&0&1
\end{bmatrix}
$$

Il y a, par contre, de choses importantes √† remarquer :

- $M^n$ donne la matrice des chemins de **longueur strictement √©gale √† $n$**, et non pas de longueur inf√©rieur ou √©gale √† $n$.
- Partant de $A$ jusqu‚Äô√† $B$, il n‚Äôexiste pas un chemin de longueur 1 mais de longueur 2.
- Partant de $A$ jusqu‚Äô√† $E$, il existe un chemin de longueur 1, mais pas de longueur 2.
- Partant de $B$ jusqu‚Äô√† $C$, il existe **deux** chemins de longueur 2 !

## Fermeture transitive

La fermeture transitive est un op√©ration qui prend un graphe et retourne un autre graphe. En particulier, s‚Äôil existe un chemin partant de $v_i$ √† $v_j$ de n‚Äôimporte quelle longueur, on rajoute un arc direct $(v_i,v_j)$. 

![Graphe de d√©part √† gauche, sa fermeture transitive √† droite.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_3.png)

Graphe de d√©part √† gauche, sa fermeture transitive √† droite.

En particulier, pour d√©terminer la fermeture transitive $\tilde{M}_G$ un graphe $G$ √† $n$ sommets, l‚Äôop√©ration est comme suit :

$$
\tilde{M}_G= M_G\oplus M^{[2]}_G\oplus\dots\oplus M^{[n]}_G=\bigoplus_{i=0}^n M^{[i]}_G
$$

O√π $\oplus$ est l‚Äôaddition bool√©enne et $M^{[n]}$ est la $n$-i√®me puissance bool√©enne de $M$.

- $M^{[n]}$ reemplace chaque entr√©e $m_{ij}$ avec $0$ si $m_{ij} = 0$ et $1$ si $m_{ij} > 0$.
Basiquement, nous dit s‚Äôil existe au moins un chemin entre deux sommets si $1$ et $0$ sinon.
- L‚Äôaddition bool√©enne $a\oplus b$ est $0$ si $a+b=0$, et $1$ si $a+b>0$.

Donc, pour ce graphe $G$ :

$$
M_G^{[1]}=
\begin{bmatrix}
0&1&0\\
1&0&1\\
0&0&0
\end{bmatrix},\space
M_G^{[2]}=
\begin{bmatrix}
1&0&1\\
0&1&0\\
0&0&0
\end{bmatrix},\space
M_G^{[3]}=
\begin{bmatrix}
0&1&0\\
1&0&1\\
0&0&0
\end{bmatrix}
\\
\text{}
\\
\tilde{M}_G=M^{[1]}\oplus M^{[2]}\oplus M^{[3]}=
\begin{bmatrix}
1&1&1\\
1&1&1\\
0&0&0
\end{bmatrix}
$$

Finalement, chaque entr√©e de $\tilde{M}_G$ devrait s‚Äôinterpreter comme s‚Äôil existe au moins un chemin de taille √©gale ou inf√©rieur √† $n$ qui va de $v_i$ √† $v_j$ si $\tilde{m}_{ij}=1$, et $0$ sinon.

# Graphes non-orient√©s

## D√©finition

En diff√©rence avec les graphes orient√©s, les arcs d‚Äôun graphe non-orient√© pourrait √™tre consid√©r√©s bidirectionnels. Il n‚Äôest plus important la direction, mais la connexion entre deux sommet. Comme √ßa, on n‚Äôa plus besoin de sp√©cifier la direction de chaque arc.

![Un graphe oriente.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_4.png)

Un graphe orient√©.

![Le m√™me graphe, mais non-oriente.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_5.png)

Le m√™me graphe, mais non-orient√©.

Le vocabulaire des graphes non-orient√©s change par rapport √† ceux orient√©s : les chemins sont appel√©s des *cha√Ænes* ; les chemins √©l√©mentaires (dont *hamiltoniens*) et simples sont les cha√Ænes √©l√©mentaires et simples ; et, parfois, les arcs dans les graphes non-orient√©s sont appel√©s *ar√™tes*.

Pour d√©duire la matrice d‚Äôadjacence $M_{G^\prime}$ d‚Äôun graphe non-orient√© √† partir de celle d‚Äôun graphe orient√©, on le fait en deux parties :

1. On inverses **toutes** les directions du graphe orient√©, ce qui serait la m√™me chose que transposer $M_{G}$, donc on obtient un graphe dont la matrice d‚Äôadjacence est $M_G^t$.
2. On l‚Äôadditione avec la matrice du graphe original, pour obtenir celle du graphe orient√©.
On notera qu‚Äôon a √©t√© oblig√© d‚Äôorienter deux fois la boucle sur $C$, d‚Äôo√π le coefficient $2$ sur la diagonale. Aussi, la matrice $M_{G^*}$ est sym√©trique (par rapport √† la diagonale).
    
    $$
    M_{G^*}=M_G+M_{G}^t
    $$
    

Un sommet $v$ est dit **connexe** si, pour tous les autres sommets $w$ ($w\ne v$), il existe une **cha√Æne** (√©quivalence de chemin d‚Äôun graphe non orient√©) reliant $v$ √† $w$. Bref, √† partir de $v$, on peut arriver √† tout autre sommet du graphe. Un graphe est **connexe** si tous ses sommets sont connexes.

## Arbres

Un arbre est un graphe non-orient√© qui est connexe, mais aussi qui est *acyclique*, c√†d. qui ne poss√®de pas de *cycles*. Un cycle est juste la notion de circuit mais pour dans les graphes non-orient√©s.

En d‚Äôautres termes, un arbre est un graphe non-orient√© o√π pour toute couple de sommets $(v_i,v_j)$, il existe **strictement et exactement** une seul cha√Æne qui les connecte. Ceci implique qu‚Äôune cha√Æne d‚Äôun sommet vers lui-m√™me peut √™tre coup√© en deux : une ‚Äúsous-cha√Æne‚Äù o√π on s‚Äô√©loigne du sommet et une autre cha√Æne o√π on revient au sommet. La deuxi√®me cha√Æne est l‚Äôinverse de la premi√®re.

Dans l‚Äôexemple dessous, si on pars et revient √† $6$ passant par $2$, on va en premier √† $2$ et puis on fait exactement la sous-cha√Æne inverse.

![Un arbre.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_6.png)

Un arbre.

[Cycle (graph theory)](https://en.wikipedia.org/wiki/Cycle_(graph_theory))

[Connectivity (graph theory)](https://en.wikipedia.org/wiki/Connectivity_(graph_theory)#Connected_vertices_and_graphs)

[Tree (graph theory)](https://en.wikipedia.org/wiki/Tree_(graph_theory))

## Graphes pond√©r√©s

Un graphe pond√©r√© est un graphe dont les arcs ont des valeurs correspondants. On d√©fini aussi la ‚Äúvaleur‚Äù d‚Äôun chemin de $v_i$ √† $v_j$ comme la somme des valeurs de arcs qui le composent. **Le graphe pond√©r√© peut-√™tre orient√© ou non-orient√©**.

![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_7.png)

Par exemple, dans ce graphe pond√©r√© :

- Le chemin $(B,A,E,C)$ vaut $4+3+5=12$
- Le chemin $(B,D,E,C)$ vaut $7+4+5=16$
- Le chemin $(B,D,C)$ vaut $7+8=15$

Parmi ces chemins, le chemin minimal est (1) et le maximal est (2).

## L‚Äôalgorithme de Dijkstra : recherche du chemin le plus court

Avant de commence, le terme ‚Äúdistance‚Äù dans le contexte de l‚Äôalgorithme de Dijkstra est juste la valeur de l‚Äôarc qui connecte un sommet avec un autre, et non pas la longueur d‚Äôun chemin. On pourrait penser que la valeur d‚Äôun arc repr√©sente les kilom√®tres entre les deux sommets.

<aside>
üíª En reformulant plus simplement :

1. On marque tous les sommets comme non visit√©s.
2. On donne √† tous les sommets une distance provisoire : $0$ au sommet source et $\infin$ aux autres. Aussi, on marque le sommet source comme sommet courant.
3. Pour tous les voisins non visit√©s du sommet courant :
    1. On calcule la distance √† travers le sommet courant (distance accumul√© depuis le sommet source + la distance du passage direct).
    2. Si cette nouvelle distance est plus courte que la distance provisoire existante, on la remplace et on garde en t√™te le chemin qui la produit, sinon on garde la pr√©c√©dente.
4. Quand on ait fini, on marque le sommet courant comme visit√©.
5. On v√©rifie si le sommet destination a √©t√© marqu√© visit√©.
    1. Si oui, on arr√™te, on a fini l‚Äôalgorithme.
    2. Sinon, on marque comme sommet courant celui qui n‚Äôest pas encore marqu√© comme visit√© et qui a la distance provisoire la plus petite. **On r√©p√®te d√®s l‚Äô√©tape 3**.
</aside>

**Note** : un axiome courant en math√©matiques dit que si on a le chemin le plus court entre un point et un autre, alors, si on prend un point de ce chemin, la suite du chemin est encore le chemin le plus court de ce point vers l‚Äôextr√©mit√©.

[Dijkstra&#039;s algorithm](https://en.wikipedia.org/wiki/Dijkstra's_algorithm)

### Exemple

1. Sur un graphe pond√©r√©, orient√© ou non, on se donne un sommet d‚Äôentr√©e (sommet source), disons $A$. On fixe la distance √† lui-m√™me √† $0$.  On gardera en t√™te les sommets visit√©s et les non-visit√©s. On marque le sommet $A$ comme le sommet courant et comme sommet visit√©.
    
    ![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_8.png)
    
2. Pour tous les sommets diff√©rents de la source, on marque que leur distance provisoire est infinie. On la marque sur les sommets.
    
    ![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_9.png)
    
3. Pour chaque successeur non visit√© de $A$ ($B$,$D$ et $E$), on compare si la distance directe (la valeur de l‚Äôarc que les connecte) est plus petite que leur distance provisionnelle. On garde la distance la plus petite entre les deux comme la ***nouvelle* distance provisoire**.
    
    ![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_10.png)
    
4. On marque $A$ comme sommet visit√©, sa distance provisoire comme distance plus courte d√©finitive, on le rougit (c‚Äô√©tait d√©j√† rougit mais quand m√™me) et on recommence s√©lectionnant le sommet non visit√© avec la distance provisoire la plus petite, dans ce cas $E$. Le voisins non visit√© de $E$ est juste $D$.
    1. Dans ce cas, la somme de la distance cumul√©e ($6$) et la distance directe ($3$) est plus petite que la distance provisoire de $D$ ($10$) $(A,E,D)=9$ est plus court que $(A,D)=10$, donc on rougit $E$ et **on le redonne une nouvelle distance provisoire**.
    2. Pour B, la distance plus courte est la distance directe. On ne les rougit pas.
    3. On marque sur les sommets successeurs directes leurs distances plus courtes et **finalement on marque les successeurs comme des sommets visit√©s**. Leurs distances provisoires √† ce moment l√† deviennent leurs distance plus courtes √† partir du sommet source ($A$). Notons que sur $D$, la distance plus court est $9$ (passant par $E$) et non pas $10$ (passage directe).
    
    ![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_11.png)
    
5. On r√©p√®te avec tous les autres sommets non-visit√©s jusqu‚Äô√† arriver √† notre sommet destination.
    1. Pour $C$, on cherche ses pr√©d√©cesseurs directes qui sont aussi visit√©s ($F$ est pr√©d√©cesseur mais pas visit√© encore, donc on ne le consid√®re pas). Apr√®s, on cherche le minimum √† partir de ces sommets, comptant la distance depuis $A$ et ajoutant la distance directe √† $C$.
        1. Pour $B$, √ßa serait $7+7=14$.
        2. Pour $D$, √ßa serait $9+2=11$. Il est le chemin le plus court.
        3. Le chemin le plus court de $A$ √† $C$ est donc $(A,E,D,C)$.
        4. On marque $C$ comme visit√© et on rougit le pr√©d√©cesseur qui a minimis√© la distance, c√†d. $D$.
    2. De m√™me pour $F$, cette fois connaissant la distance la plus courte √† $C$. Ses pr√©d√©cesseurs visit√©s sont $C$ et $D$.
        1. $C$ est de distance directe $5$ et distance cumul√©e $11$. Donc, la distance du chemin plus court de $A$ √† $F$ passant par $C$ est $5+11=16$.
        2. $D$ de distance directe $9$ et distance cumul√©e $9$ aussi. Donc, la distance du chemin plus court de $A$ √† $F$ passant par $D$ est $9+9=18$.
        3. Passer par $C$ donne un chemin plus courte. Donc, on donne √† $F$ comme distance plus courte $16$, on le marque visit√© et on rougit le pr√©d√©cesseur qui a minimisait la distance, c√†d $C$.
    
    ![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_12.png)
    
6. Si on arrive marque visit√© notre sommet destination, on le rougit et on a fini l‚Äôalgorithme.

# Ordonnancement

[Slides d‚Äôordonnancement](slides_ordonnancement_minfo_annote.pdf)

## Dessin d‚Äôun graphe par niveaux

On peut dire qu‚Äôun sommet dans un graphe est de niveau $0$ s‚Äôil n‚Äôas pas de pr√©d√©cesseur dans l‚Äôensemble de sommets $S$. L‚Äôensemble de sommets de niveau 0 est not√© $S_0$. Ayant d√©fini $S_0$, on peut d√©finir $S_n$ r√©cursivement comme suit :

$$
S_n = S - S_{n-1}
$$

![Cette m√©thode √©crire, de gauche √† droite, les sommes de $S_0$ jusqu‚Äô√† $S_n$ resulte en des graphes bien ordonn√©s comme celui-ci.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_13.png)

Cette m√©thode √©crire, de gauche √† droite, les sommes de $S_0$ jusqu‚Äô√† $S_n$ resulte en des graphes bien ordonn√©s comme celui-ci.

Le but de l‚Äôordonnancement, si on voit les sommets comme des t√¢ches, est de parcourir toutes les t√¢ches du graphe par niveau. Par exemple, pour $E$, les t√¢ches $BDA$ doivent √™tre faites.

## MPM : M√©thode des potentiels metra

La r√©alisation d‚Äôun projet passe par l‚Äôex√©cution de diff√©rentes t√¢ches, de dur√©es souvent diff√©rentes. Si certaines t√¢ches peuvent √™tre r√©alis√©es simultan√©ment, d‚Äôautres n√©cessitent que certaines t√¢ches aient √©t√© r√©alis√©es ant√©rieurement. Faire l‚Äôordonnancement d‚Äôun projet consiste √† organiser ce projet en respectant les contraintes d‚Äôant√©riorit√© des t√¢ches tout en minimisant la dur√©e totale de r√©alisation.

<aside>
‚ùó La m√©thode MPM (M√©thode des potentiels metra) permet l‚Äôordonnancement de projets, c‚Äôest la m√©thode que nous exposerons dans ce cours. Nous aurions pu choisir la m√©thode PERT, mais elle est plus complexe √† mettre en oeuvre.

</aside>

Reprenons le graphe pr√©c√©dente, on l‚Äôajoute un sommet ‚Äúfin‚Äù apr√®s $C$ et, √† chaque arc, on ajoute un num√©ro qui repr√©sentera les unit√©s de temps pour compl√©ter la t√¢che et passer √† la suivante.

![untitled](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_14.png)

Ayant ce graphe comme base, on va s‚Äôint√©resser √† construire deux indicateurs :

- Date au plus t√¥t : la date √† laquelle on peut d√©marrer une t√¢che **sans en avoir rat√©**.
- Date au plus tard : la date la plus tardive √† laquelle on peut d√©marrer une t√¢che sans **retarder le projet**.

On doit en premier calculer les dates au plus t√¥t des toutes les t√¢ches pour pouvoir construire la date au plus tard.

### Date au plus t√¥t : $t(X)$

On denote la date au plus t√¥t du sommet $B$ comme $t(B)$. En plus, on notera par la suite la dur√©e du passage d‚Äôune tache √† une autre comme $d(B,D)$ (le cas de la dur√©e de $B$ √† $D$, par exemple). On note que $d(X,X)=0$.

1. On fixe un indice $i=0$. On commence en √©valuant $t(s_0)$, pour tous les sommets $s_0$ de $S_0$. Trivialement, on peut les commencer imm√©diatement car elles sont les toutes premi√®res t√¢ches, donc $\forall s_0 \in S_0,\hspace{4pt} t(s_0) = 0$.
2. On passe √† $i=1$, on calcule $S_1 = S - S_0$. Pour $D$ et $A$, on voit que la seule mani√®re de les commencer c‚Äôest de passer par B, donc $t(D) = d(B,D) = 2$ et $t(A) = d(B,A)=2$.
3. On voit que $t(E)=\min\big(t(D)+d(D,E), t(A)+d(A,E)\big)$. C‚Äôest-√†-dire, la date au plus t√¥t des t√¢ches pr√©d√©cesseuses plus leurs distance √† $E$. On d√©duit que $t(E)=7$, passant de D √† E. 
4. En general, si $\Gamma^-(X)$ est l‚Äôensemble de pr√©d√©cesseurs d‚Äôun sommet $X$, donc : 
    
    $$
    t(X)=
    \begin{cases}
    0, \text{ si } X\in S_0
    \\
    \max\big( \{t(s^-_X)+d(s^-_X,X): s^-_X \in \Gamma^-(X)\} \big), \text{ sinon }
    \end{cases}
    $$
    
5. Quand on arrive √† la fin, $t(\text{fin})=14$, le projet dure $14$ jours au mieux sans rat√© aucune t√¢che).

### Date au plus tard : $T(X)$

Maintenant, on va calculer la date au plus tard. La diff√©rence ici c‚Äôest qu‚Äôon commence d√®s la fin jusqu‚Äô√†ux premiers t√¢ches du projet. On rappelle que la date au plus tard est la date la plus tardive o√π on commence une t√¢che sans retarder le projet, c√†d de sorte que toutes les t√¢ches du niveau pr√©c√©dent soient compl√®tes (m√™me si les t√¢ches du niveau courant ne le sont pas).

On lance un indice $i=0$ et on fixe $n$ comme la quantit√© des niveaux de t√¢ches en total, tout √ßa pour construire l‚Äôindice qui nous int√©resse : $j = n-i$.

1. Si on commence par la fin du projet, donc $j=5$. On note que $T(\text{fin})=t(\text{fin})=14$. Bien √©videmment, la seule date √† laquelle on peut atteindre la fin du projet c‚Äôest d‚Äôavoir compl√©t√© toutes les t√¢ches.
2. On passe √† $j=4$, le sommet $C$. La date la plus tardive est donc $T(C)=T(\text{fin})-d(C,\text{fin})=14-4=10$.
3. Pour $j=3$ c‚Äôest le sommet $E$. M√™me chose : $T(E)=T(C)-d(E,C)=10-3=7$.
4. Pour $j=2$, on parle de $D$ et $A$. On commence par $A$. La chose int√©ressante ici c‚Äôest que on devra voir tous les successeurs de $A$ : $C$ et $E$, donc $T(A)=\min\big(T(C)-d(A,C),\hspace{2pt}T(E)-d(A,E)\big)$. On d√©duit aussi que $T(D)=2$.
5. En g√©n√©ral, si $\Gamma^+(X)$ est l‚Äôensemble de pr√©d√©cesseurs d‚Äôun sommet $X$, donc :

$$
T(X)=
\begin{cases}
t(\text{fin}), \text{ si } X=\text{fin}
\\
\min\big(\{T(s^+_X)-d(X,s^+_X):s^+_X \in \Gamma^+(X)\}\big), \text{ sinon}
\end{cases}
$$

### Graphique final et la marge d‚Äôune t√¢che

![Pour chaque t√¢che, on nota sa date au plus t√¥t dans la casse gauche et sa date au plus tard dans la casse droite.](new/uga/l2/s4/math/s4_math_math_pour_l‚Äôinfo/03_theorie_des_graphes/untitled_15.png)

Pour chaque t√¢che, on nota sa date au plus t√¥t dans la casse gauche et sa date au plus tard dans la casse droite.

La marge d‚Äôune t√¢che est la diff√©rence entre sa date au plus t√¥t et sa date au plus tard. Si la marge d‚Äôune t√¢che est $0$, on dit que la t√¢che est *critique*. Un chemin critique est un chemin ne contenant que des t√¢ches critiques, comme $BDEC$ par exemple.

En soi, le chemin critique n‚Äôest pas tangiblement important, mais il doit servir de r√©f√©rence pour l‚Äôorganisation du projet. **Aucune t√¢che ne peut √™tre retard√©e sans impliquer un retard de fin du projet**. Imaginons deux mani√®res de faire le projet : $BD+BAEC$ et $BA+BDEC$. La premi√®re mani√®re prend moins de temps ($14$) que la deuxi√®me ($16$).

Le chemin le plus vite est tel que, √† chaque t√¢che qu‚Äôon soit, on prend la t√¢che critique parmi les t√¢ches successeuses.